{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Smart sampling the parameter space and feature computation\n",
    "\n",
    "From the set of parameters estimated using multiple patch recordings (1 somatic, 2 apical dendrites), we simulate random perturbations using Latin Hypercube Sampling (LHS). \n",
    "\n",
    "First, we generate a large number of samples, then we select the samples which:\n",
    "\n",
    "- are the most distant between each other\n",
    "- which reproduce bAP and BAC firing\n",
    "- whose feature sets are also the most distant \n",
    "\n",
    "The random parameters are saved in the `config/params/smart_random.csv` and will be used to assess the fitting performance of different feature sets.\n",
    "\n",
    "From the set of all features, separate feature sets are computed for:\n",
    "\n",
    "- multiple\n",
    "- soma\n",
    "- extra\n",
    "\n",
    "feature sets. The output features are saved to the `config/features/random_random_id{}/` folder (in pkl format). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "from pyDOE import lhs\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from scipy.spatial import distance\n",
    "import MEAutility as mu\n",
    "import LFPy\n",
    "from copy import copy\n",
    "import neuroplotlib as nplt\n",
    "from pprint import pprint\n",
    "\n",
    "import bluepyopt as bpopt\n",
    "import bluepyopt.ephys as ephys\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2308)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model\n",
    "import evaluator\n",
    "import plotting\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_params = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load release params and bounds\n",
    "release_params_file = 'config/parameters_release.json'\n",
    "\n",
    "release_params = evaluator.get_release_params()\n",
    "params_bounds = evaluator.get_unfrozen_params_bounds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_params = len(release_params)\n",
    "n_samples = 500  # number of random samples \n",
    "lim_dev = 0.3  # limits for each param are: [release_val-lim_dev*release_val, release_val+lim_dev*release_val] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(release_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latin hypercube sampling (normal 0-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_samples = lhs(n_params, samples=n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot(random_samples[:, 5], random_samples[:, 19], random_samples[:, 3], '*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute parameters limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if True, the limits of the params config are used. Otherwise, the realeas params +- lim_dev are used\n",
    "use_params_bounds = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_lims = {}\n",
    "\n",
    "for par, val in release_params.items():\n",
    "    dev = lim_dev * val\n",
    "    lims = [val - dev, val + dev]\n",
    "    # check values based on param configs\n",
    "    if lims[0] < params_bounds[par][0]:\n",
    "        lims[0] = params_bounds[par][0]\n",
    "        print(f'Param {par} changed lower bound')                    \n",
    "    if lims[1] > params_bounds[par][1]:\n",
    "        lims[1] = params_bounds[par][1]\n",
    "        print(f'Param {par} changed upper bound')\n",
    "    param_lims[par] = lims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_lims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_samples = np.zeros_like(random_samples)\n",
    "\n",
    "for i, sample in enumerate(random_samples):\n",
    "    for j, (par, parlim) in enumerate(param_lims.items()):\n",
    "        scaled_samples[i, j] = (parlim[1] - parlim[0]) * sample[j] + parlim[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in scaled_samples:\n",
    "    for j, (par, parlim) in enumerate(param_lims.items()):\n",
    "        assert parlim[0] < sample[j] < parlim[1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select *distant* parameters\n",
    "\n",
    "First we iteratively look for parameters distan from each other in the original normalized space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_target_samples = 45 # 50\n",
    "min_dist = 0.2\n",
    "target_samples_idxs = []\n",
    "it = 0\n",
    "max_iter = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while it < max_iter:\n",
    "    if np.mod(it, 100) == 0:\n",
    "        print(f\"Iteration {it+1}/{max_iter}\")\n",
    "        \n",
    "    if len(target_samples_idxs) == 0:\n",
    "        random_sample_id = np.random.permutation(len(random_samples))[0]\n",
    "        print(f'Added {random_sample_id}')\n",
    "        target_samples_idxs.append(random_sample_id)\n",
    "    else:\n",
    "        # compute distances\n",
    "        all_samples = np.arange(len(scaled_samples))\n",
    "        dists = np.zeros((len(target_samples_idxs), len(random_samples)))\n",
    "        for i, target_id in enumerate(target_samples_idxs):\n",
    "            target = random_samples[target_id]\n",
    "            for j in all_samples:\n",
    "                dists[i, j] = distance.cosine(random_samples[j], target)\n",
    "        \n",
    "        cum_dist = []\n",
    "        possible_idxs = []\n",
    "        for col in all_samples:\n",
    "            if np.all(dists[:, col] > min_dist):\n",
    "                possible_idxs.append(col)\n",
    "                cum_dist.append(np.sum(dists[:, col]))\n",
    "        \n",
    "        if len(possible_idxs) > 0:\n",
    "            max_id = np.argmax(cum_dist)\n",
    "            random_sample_id = possible_idxs[max_id]\n",
    "            print(f'Added {random_sample_id}: Targets {len(target_samples_idxs)}')\n",
    "            dists = []\n",
    "            for t in target_samples_idxs:\n",
    "                dists.append(distance.cosine(random_samples[t], random_samples[random_sample_id]))\n",
    "            target_samples_idxs.append(random_sample_id)\n",
    "            \n",
    "    if len(target_samples_idxs) >= num_target_samples:\n",
    "        print(\"Found samples!\")\n",
    "        break\n",
    "    it += 1\n",
    "target_samples_idxs = np.array(target_samples_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(target_samples_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_params_mat = np.zeros((len(target_samples_idxs), len(target_samples_idxs)))\n",
    "for i in np.arange(len(target_samples_idxs)):\n",
    "    for j in np.arange(i+1, len(target_samples_idxs)):\n",
    "        p1 = random_samples[target_samples_idxs[i]]\n",
    "        p2 = random_samples[target_samples_idxs[j]]\n",
    "        cost = distance.cosine(p1, p2)\n",
    "        dist_params_mat[i, j] =  cost\n",
    "dist_params_array = dist_params_mat[dist_params_mat>0].ravel()\n",
    "\n",
    "plt.matshow(dist_params_mat)\n",
    "plt.colorbar()\n",
    "\n",
    "print(np.min(dist_params_array))\n",
    "print(np.max(dist_params_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_sc_params_mat = np.zeros((len(target_samples_idxs), len(target_samples_idxs)))\n",
    "for i in np.arange(len(target_samples_idxs)):\n",
    "    for j in np.arange(i+1, len(target_samples_idxs)):\n",
    "        p1 = scaled_samples[target_samples_idxs[i]]\n",
    "        p2 = scaled_samples[target_samples_idxs[j]]\n",
    "        cost = distance.cosine(p1, p2)\n",
    "        dist_sc_params_mat[i, j] =  cost\n",
    "dist_sc_params_array = dist_sc_params_mat[dist_sc_params_mat>0].ravel()\n",
    "\n",
    "plt.matshow(dist_sc_params_mat)\n",
    "plt.colorbar()\n",
    "\n",
    "print(np.min(dist_sc_params_array))\n",
    "print(np.max(dist_sc_params_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute full set of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_type = 'planar' # 'linear'\n",
    "electrode = model.define_probe(probe_type=probe_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = mu.plot_probe(electrode.probe)\n",
    "#nplt.plot_neuron(morphology=\"morphology/cell1.asc\", plane='xy', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l5pc_cell = model.create()\n",
    "\n",
    "param_names = [param.name for param in l5pc_cell.params.values() if not param.frozen]\n",
    "\n",
    "feature_set = 'all'\n",
    "\n",
    "print(f'Feature set {feature_set}')\n",
    "gt_responses = []\n",
    "\n",
    "if feature_set in [\"extra\", \"all\"]:\n",
    "    fitness_protocols = evaluator.define_protocols(electrode=electrode, protocols_with_lfp=[\"Step1\"])\n",
    "else:\n",
    "    fitness_protocols = l5pc_evaluator.define_protocols() \n",
    "\n",
    "if feature_set in [\"extra\", \"all\"]:\n",
    "    sim = ephys.simulators.LFPySimulator(LFPyCellModel=l5pc_cell, cvode_active=True, electrode=electrode)\n",
    "else:\n",
    "    sim = ephys.simulators.LFPySimulator(LFPyCellModel=l5pc_cell, cvode_active=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_samples = random_samples[target_samples_idxs]\n",
    "target_scaled_samples = scaled_samples[target_samples_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_params = pd.DataFrame(data=target_scaled_samples, columns=param_lims.keys(), \n",
    "                             index=[f'random_{i}' for i in range(len(target_samples_idxs))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "ax = sns.boxplot(data=random_params, orient='horizontal')\n",
    "fig = ax.get_figure()\n",
    "fig.subplots_adjust(left=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness_protocols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_features = []\n",
    "random_responses = []\n",
    "\n",
    "channels='map'\n",
    "\n",
    "for i, (index, params) in enumerate(random_params.iterrows()):\n",
    "    print(f'{i+1} / {len(random_params)}, {index}')\n",
    "    \n",
    "    feature_folder = f'config/features/{index}'\n",
    "    _, response, feature_dict = evaluator.compute_feature_values(params, l5pc_cell, fitness_protocols, sim, \n",
    "                                                                 feature_set=feature_set, probe=electrode.probe, \n",
    "                                                                 channels=channels,\n",
    "                                                                 feature_folder=feature_folder,\n",
    "                                                                 save_to_file=False)\n",
    "    random_features.append(feature_dict)\n",
    "    random_responses.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_multiple_responses(random_responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude params that do not express bAP firing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_features_v = utils.vectorize_features(random_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_bap = []\n",
    "bap_ap_min = 50\n",
    "min_fr_step1 = 10\n",
    "for i, gt in enumerate(list(random_features_v)):\n",
    "    bap_feat = [k for k in gt.keys() if 'bAP' in k]\n",
    "    bac_feat = [k for k in gt.keys() if 'BAC' in k]\n",
    "    if len(bap_feat) == 5 and len(bac_feat) == 5:\n",
    "#         ap_amplitude_from_voltagebase = gt['bAP.dend1.Spikecount']\n",
    "#         fr_step_1 = gt['Step1.soma.mean_frequency']\n",
    "#         if ap_amplitude_from_voltagebase >= bap_ap_min and fr_step_1 >= min_fr_step1:\n",
    "        bap_spike_sount = gt['bAP.soma.Spikecount']\n",
    "        if bap_spike_sount == 1:\n",
    "            complete_bap.append(i)\n",
    "bap_sample_idxs = np.array(complete_bap)\n",
    "print(f\"Samples with complete bAP response: {len(complete_bap)} / {len(random_features_v)}\")\n",
    "\n",
    "bap_features_v = np.array(random_features_v)[bap_sample_idxs]\n",
    "bap_features = np.array(random_features)[bap_sample_idxs]\n",
    "bap_responses = np.array(random_responses)[bap_sample_idxs]\n",
    "bap_scaled_samples = target_scaled_samples[bap_sample_idxs]\n",
    "bap_random_samples = target_samples[bap_sample_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_multiple_responses(bap_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can select a subset of extracellular channels to compute features on (if None, all channels are used)\n",
    "channels=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_feat_mat = np.zeros((len(bap_sample_idxs), len(bap_sample_idxs)))\n",
    "for i in np.arange(len(bap_sample_idxs)):\n",
    "    for j in np.arange(i+1, len(bap_sample_idxs)):\n",
    "        f1 = bap_features_v[i]\n",
    "        f2 = bap_features_v[j]\n",
    "        \n",
    "        selected_keys = []\n",
    "        for k in f1.keys():\n",
    "            if 'MEA' not in k:\n",
    "                selected_keys.append(k)\n",
    "#             else:\n",
    "#                 if channels is not None:\n",
    "#                     if int(k[-1]) in channels:\n",
    "#                         selected_keys.append(k)\n",
    "#                 else:\n",
    "#                     selected_keys.append(k)\n",
    "                        \n",
    "        f1_val, f2_val = [], []\n",
    "        for k in selected_keys:\n",
    "            if k in f1 and k in f2:\n",
    "                if np.isfinite(f1[k]) and np.isfinite(f2[k]):\n",
    "                    f1_val.append(f1[k])\n",
    "                    f2_val.append(f2[k])\n",
    "        cost = distance.cosine(f1_val, f2_val)\n",
    "        if np.isnan(cost):\n",
    "            print(f1_val, f2_val)\n",
    "        dist_feat_mat[i, j] =  cost\n",
    "        \n",
    "dist_feat_array = dist_feat_mat[dist_feat_mat>0].ravel()\n",
    "\n",
    "plt.matshow(dist_feat_mat)\n",
    "plt.colorbar()\n",
    "\n",
    "print(np.min(dist_feat_array))\n",
    "print(np.max(dist_feat_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select samples with the most distant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_final_samples = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dist_matrix symmetric\n",
    "dist_feat_sym = copy(dist_feat_mat)\n",
    "\n",
    "for i in np.arange(len(bap_sample_idxs)):\n",
    "    for j in np.arange(i+1, len(bap_sample_idxs)):\n",
    "        dist_feat_sym[j, i] = dist_feat_sym[i, j]\n",
    "plt.matshow(dist_feat_sym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select samples based on cumulative distance\n",
    "cum_dist = np.sum(dist_feat_sym, 0)\n",
    "max_dist_idxs = np.argsort(cum_dist)[::-1][:num_final_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cum_dist[max_dist_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_sample_idxs = max_dist_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_scaled_params = bap_scaled_samples[selected_sample_idxs]\n",
    "selected_random_params = bap_random_samples[selected_sample_idxs]\n",
    "selected_responses = bap_responses[selected_sample_idxs]\n",
    "selected_features_v = bap_features_v[selected_sample_idxs]\n",
    "selected_features = bap_features[selected_sample_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_sel_random_params_mat = np.zeros((len(selected_random_params), len(selected_random_params)))\n",
    "dist_sel_scaled_params_mat = np.zeros((len(selected_random_params), len(selected_random_params)))\n",
    "dist_sel_features_mat = np.zeros((len(selected_random_params), len(selected_random_params)))\n",
    "for i in np.arange(len(selected_random_params)):\n",
    "    for j in np.arange(i+1, len(selected_random_params)):\n",
    "        p1 = selected_random_params[i]\n",
    "        p2 = selected_random_params[j]\n",
    "        dist_sel_random_params_mat[i, j] =  distance.cosine(p1, p2)\n",
    "        \n",
    "        p1 = selected_scaled_params[i]\n",
    "        p2 = selected_scaled_params[j]\n",
    "        dist_sel_scaled_params_mat[i, j] =  distance.cosine(p1, p2)\n",
    "        \n",
    "        f1 = selected_features_v[i]\n",
    "        f2 = selected_features_v[j]\n",
    "        \n",
    "        selected_keys = []\n",
    "        for k in f1.keys():\n",
    "            if 'MEA' not in k:\n",
    "                selected_keys.append(k)\n",
    "#             else:\n",
    "#                 if channels is not None:\n",
    "#                     if int(k[-1]) in channels:\n",
    "#                         selected_keys.append(k)\n",
    "#                 else:\n",
    "#                     selected_keys.append(k)\n",
    "                        \n",
    "        f1_val, f2_val = [], []\n",
    "        for k in selected_keys:\n",
    "            if k in f1 and k in f2:\n",
    "                if np.isfinite(f1[k]) and np.isfinite(f2[k]):\n",
    "                    f1_val.append(f1[k])\n",
    "                    f2_val.append(f2[k])\n",
    "        dist_sel_features_mat[i, j] = distance.cosine(f1_val, f2_val)\n",
    "        \n",
    "# dist_params_array = dist_params_mat[dist_params_mat>0].ravel()\n",
    "\n",
    "plt.matshow(dist_sel_random_params_mat)\n",
    "plt.title(\"Norm params\")\n",
    "plt.colorbar()\n",
    "\n",
    "plt.matshow(dist_sel_scaled_params_mat)\n",
    "plt.title(\"Scaled params\")\n",
    "plt.colorbar()\n",
    "\n",
    "plt.matshow(dist_sel_features_mat)\n",
    "plt.title(\"Features\")\n",
    "plt.colorbar()\n",
    "\n",
    "# print(np.min(dist_params_array))\n",
    "# print(np.max(dist_params_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_multiple_responses(responses_list=selected_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3 = plt.figure()\n",
    "ax3 = fig3.add_subplot(111)\n",
    "cmap=plt.get_cmap('viridis')\n",
    "for i, gt in enumerate(selected_responses):\n",
    "    eap = evaluator.calculate_eap(responses=gt, protocols=fitness_protocols,\n",
    "                                  protocol_name='Step1')\n",
    "    eap_norm = eap / np.max(np.abs(eap), 1, keepdims=True)\n",
    "    mu.plot_mea_recording(eap_norm, \n",
    "                          electrode.probe, colors=f\"C{i}\", ax=ax3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creata dataframe\n",
    "df_release = pd.DataFrame(data=release_params, index=['release'])\n",
    "df_random = pd.DataFrame(data=selected_scaled_params, columns=param_lims.keys(), \n",
    "                         index=[f'random_{i}' for i in range(len(selected_scaled_params))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "ax = sns.boxplot(data=df_random, orient='horizontal')\n",
    "fig = ax.get_figure()\n",
    "fig.subplots_adjust(left=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double check that responses are correct!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_params_file = 'config/params/smart_random.csv'\n",
    "loaded_params = pd.read_csv(loaded_params_file, index_col='index')\n",
    "loaded_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_type = 'planar' # 'linear'\n",
    "electrode = model.define_probe(probe_type=probe_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l5pc_cell = model.create()\n",
    "channels='map'\n",
    "\n",
    "param_names = [param.name for param in l5pc_cell.params.values() if not param.frozen]\n",
    "\n",
    "feature_set = 'all'\n",
    "\n",
    "print(f'Feature set {feature_set}')\n",
    "gt_responses = []\n",
    "\n",
    "if feature_set in [\"extra\", \"all\"]:\n",
    "    fitness_protocols = evaluator.define_protocols(electrode=electrode, protocols_with_lfp=[\"Step1\"])\n",
    "else:\n",
    "    fitness_protocols = l5pc_evaluator.define_protocols() \n",
    "\n",
    "if feature_set in [\"extra\", \"all\"]:\n",
    "    sim = ephys.simulators.LFPySimulator(LFPyCellModel=l5pc_cell, cvode_active=True, electrode=electrode)\n",
    "else:\n",
    "    sim = ephys.simulators.LFPySimulator(LFPyCellModel=l5pc_cell, cvode_active=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_responses = []\n",
    "\n",
    "for i, (index, params) in enumerate(loaded_params.iterrows()):\n",
    "    print(f'{i+1} / {len(loaded_params)}, {index}')\n",
    "    \n",
    "    feature_folder = f'config/features/{index}'\n",
    "    _, response, feature_dict = evaluator.compute_feature_values(params, l5pc_cell, fitness_protocols, sim, \n",
    "                                                                 feature_set=feature_set, probe=electrode.probe, \n",
    "                                                                 channels=channels,\n",
    "                                                                 feature_folder=feature_folder,\n",
    "                                                                 save_to_file=False)\n",
    "    loaded_responses.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_multiple_responses(responses_list=loaded_responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save random and releas parameters to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_params:\n",
    "    params_folder = Path('config/params')\n",
    "\n",
    "    if not params_folder.is_dir():\n",
    "        os.makedirs(params_folder)\n",
    "\n",
    "    release_params_file = params_folder / 'release.csv'\n",
    "    random_params_file = params_folder / 'smart_random.csv'\n",
    "\n",
    "    df_release.to_csv(release_params_file, index_label='index')\n",
    "    df_random.to_csv(random_params_file, index_label='index')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute and save feature sets and responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_feature_set_from_all_feats(all_feat_dict, feature_output_folder, feature_list_file, \n",
    "                                    feature_set, probe):\n",
    "    feature_output_folder = Path(feature_output_folder)\n",
    "    feature_output_folder.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    feature_list = json.load(open(feature_list_file))[feature_set]\n",
    "    \n",
    "    feature_meanstd = {}\n",
    "    for protocol_name, locations in feature_list.items():\n",
    "        feature_meanstd[protocol_name] = {}\n",
    "        for location, feats in locations.items():\n",
    "            if location not in feature_meanstd[protocol_name]:\n",
    "                feature_meanstd[protocol_name][location] = {}\n",
    "            \n",
    "            for feat in feats:\n",
    "                feature_meanstd[protocol_name][location][feat] = all_feat_dict[protocol_name][location][feat]\n",
    "                \n",
    "    feature_file = feature_output_folder / f'{feature_set}.pkl'\n",
    "    with feature_file.open('wb') as f:\n",
    "        pickle.dump(feature_meanstd, f)\n",
    "            \n",
    "    # save probe\n",
    "    if not (Path(feature_output_folder) / 'probe.json').is_file():\n",
    "        with (Path(feature_output_folder) / 'probe.json').open('w') as f:\n",
    "            json.dump(probe.info, f, indent=4)\n",
    "            \n",
    "    return feature_meanstd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_sets = [\"multiple\", \"soma\", \"extra\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {}\n",
    "\n",
    "for i, all_feats in enumerate(selected_features):\n",
    "    features[i] = {}\n",
    "    for feat_set in feature_sets:\n",
    "        featsdict = save_feature_set_from_all_feats(all_feats, f'config/features/random_{i}', \n",
    "                                                   'config/features_list.json', feat_set, electrode.probe)\n",
    "        features[i][feat_set] = featsdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, responses in enumerate(selected_responses):\n",
    "    with open(f'config/features/random_{i}/responses.pkl', 'wb') as f:\n",
    "        pickle.dump(responses, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[0]['multiple']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
