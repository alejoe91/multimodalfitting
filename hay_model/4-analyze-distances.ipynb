{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze and evaluate optimization output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from scipy.spatial import distance\n",
    "\n",
    "import bluepyopt as bpopt\n",
    "import bluepyopt.ephys as ephys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import MEAutility as mu\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import LFPy\n",
    "from pathlib import Path\n",
    "\n",
    "import l5pc_model\n",
    "import l5pc_evaluator\n",
    "import l5pc_plot\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to turn feature dicitonary into a list\n",
    "def vectorize_features(feature_list):\n",
    "    feature_vectors = []\n",
    "    for feature in feature_list:\n",
    "        feature_vector = {}\n",
    "        for prot, prot_dict in feature.items():\n",
    "            for loc, loc_feat in prot_dict.items():\n",
    "                for feat, feat_val in loc_feat.items():\n",
    "                    feature_vector[f'{prot}.{loc}.{feat}'] = feat_val[0]\n",
    "        feature_vectors.append(feature_vector)\n",
    "    return feature_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiple_responses(responses_list, colors=None, return_fig=False):\n",
    "    responses = responses_list[0]\n",
    "    resp_no_mea = []\n",
    "    for (resp_name, response) in sorted(responses.items()):\n",
    "        if 'MEA' not in resp_name:\n",
    "            resp_no_mea.append(resp_name)\n",
    "    fig, axes = plt.subplots(len(resp_no_mea), figsize=(10, 10))\n",
    "    for i, responses in enumerate(responses_list):\n",
    "        if colors is None:\n",
    "            color = f'C{i}'\n",
    "        else:\n",
    "            color = colors[i]\n",
    "        for index, resp_name in enumerate(sorted(resp_no_mea)):\n",
    "            response = responses[resp_name]\n",
    "            axes[index].plot(response['time'], response['voltage'], label=resp_name, color=color)\n",
    "            axes[index].set_title(resp_name)\n",
    "    fig.tight_layout()\n",
    "    fig.show()\n",
    "\n",
    "    if return_fig:\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load gt params and optimization output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_folder = Path('tanguy_data/')\n",
    "config_folder = Path('config')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_params = pd.read_csv(config_folder / 'params' / 'smart_random.csv', index_col='index')\n",
    "random_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open(result_folder / 'runs_new.pkl', 'rb'))\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0].params_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "### Compute complete set of features for all samples\n",
    "\n",
    "soma + bap + extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mea_positions = np.zeros((20, 3))\n",
    "mea_positions[:, 2] = 20\n",
    "mea_positions[:, 1] = np.linspace(-500, 1000, 20)\n",
    "probe = mu.return_mea(info={'pos': list([list(p) for p in mea_positions]), 'center': False, 'plane': 'xy'})\n",
    "electrode = LFPy.RecExtElectrode(probe=probe, method='linesource')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = None\n",
    "\n",
    "morphology = ephys.morphologies.NrnFileMorphology('morphology/C060114A7.asc', do_replace_axon=True)\n",
    "param_configs = json.load(open('config/parameters.json'))\n",
    "parameters = l5pc_model.define_parameters()\n",
    "mechanisms = l5pc_model.define_mechanisms()\n",
    "\n",
    "l5pc_cell = ephys.models.LFPyCellModel('l5pc', \n",
    "                                       v_init=-65., \n",
    "                                       morph=morphology, \n",
    "                                       mechs=mechanisms, \n",
    "                                       params=parameters)\n",
    "\n",
    "param_names = [param.name for param in l5pc_cell.params.values() if not param.frozen]      \n",
    "feature_set = 'all'\n",
    "\n",
    "print(f'Feature set {feature_set}')\n",
    "gt_responses = []\n",
    "\n",
    "if feature_set in [\"extra\", \"all\"]:\n",
    "    fitness_protocols = l5pc_evaluator.define_protocols(electrode) \n",
    "else:\n",
    "    fitness_protocols = l5pc_evaluator.define_protocols() \n",
    "\n",
    "if feature_set in [\"extra\", \"all\"]:\n",
    "    sim = ephys.simulators.LFPySimulator(LFPyCellModel=l5pc_cell, cvode_active=True, electrode=electrode)\n",
    "else:\n",
    "    sim = ephys.simulators.LFPySimulator(LFPyCellModel=l5pc_cell, cvode_active=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (result_folder / 'feats_responses.pkl').is_file():\n",
    "    feats_responses = pickle.load((result_folder / 'feats_responses.pkl').open('rb'))\n",
    "    feats = feats_responses['feats']\n",
    "    responses = feats_responses['responses']\n",
    "    gt_features_v = feats['gt']\n",
    "    gt_responses = responses['gt']\n",
    "    fitted_features_v = feats['fitted']\n",
    "    fitted_responses = responses['fitted']\n",
    "    compute_feats_responses = False\n",
    "else:\n",
    "    compute_feats_responses = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute GT features and responses\n",
    "if compute_feats_responses:\n",
    "    gt_features = []\n",
    "    gt_responses = []\n",
    "    for i, (index, params) in enumerate(random_params.iterrows()):\n",
    "        print(f'{i+1} / {len(random_params)}, {index}')\n",
    "\n",
    "        feature_folder = f'config/features/{index}'\n",
    "        _, response, feature_dict = l5pc_evaluator.compute_feature_values(params, l5pc_cell, fitness_protocols, sim, \n",
    "                                                                          feature_set=feature_set, probe=probe, \n",
    "                                                                          channels=channels,\n",
    "                                                                          feature_folder=feature_folder,\n",
    "                                                                          save_to_file=False)\n",
    "        gt_features.append(feature_dict)\n",
    "        gt_responses.append(response)\n",
    "    gt_features_v = vectorize_features(gt_features)\n",
    "else:\n",
    "    print(\"Using loaded GT features and responses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute fitted features and responses\n",
    "if compute_feats_responses:\n",
    "    fitted_features = []\n",
    "    fitted_responses = []\n",
    "    for i, (index, fit) in enumerate(df.iterrows()):\n",
    "        params = pd.Series(data=fit['best_params'], index=fit['params_name'])\n",
    "        print(f'{i+1} / {len(df)}')\n",
    "\n",
    "        feature_folder = f'config/features/{index}'\n",
    "        _, response, feature_dict = l5pc_evaluator.compute_feature_values(params, l5pc_cell, fitness_protocols, sim, \n",
    "                                                                          feature_set=feature_set, probe=probe, \n",
    "                                                                          channels=channels,\n",
    "                                                                          feature_folder=feature_folder,\n",
    "                                                                          save_to_file=False)\n",
    "        fitted_features.append(feature_dict)\n",
    "        fitted_responses.append(response)\n",
    "    fitted_features_v = vectorize_features(fitted_features)\n",
    "else:\n",
    "    print(\"Using loaded FITTED features and responses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiple_responses(gt_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save features\n",
    "save_features = True\n",
    "if save_features and compute_feats_responses:\n",
    "    feats = {'gt': gt_features_v, 'fitted': fitted_features_v}\n",
    "    responses = {'gt': gt_responses, 'fitted': fitted_responses}\n",
    "    dump_dict = {'feats': feats, 'responses': responses}\n",
    "    with (result_folder / 'feats_responses.pkl').open('wb') as f:\n",
    "        pickle.dump(dump_dict, f)\n",
    "else:\n",
    "    print(\"Responses and features already saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check all GT params produce responses with all BAP features (5)\n",
    "complete_bap = []\n",
    "for i, gt in enumerate(list(gt_features_v)):\n",
    "    bap_feat = [k for k in gt.keys() if 'bAP' in k]\n",
    "    if len(bap_feat) == 5:\n",
    "        complete_bap.append(i)\n",
    "print(len(complete_bap))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distances = []\n",
    "param_distances_apical = []\n",
    "param_distances_somatic = []\n",
    "param_distances_axonal = []\n",
    "\n",
    "feature_distances = []\n",
    "feat_soma_dist = []\n",
    "feat_dend_dist = []\n",
    "feat_mea_dist = []\n",
    "\n",
    "# channels = [4,5,6,10,15]\n",
    "channels=None\n",
    "for i, (index, fit) in enumerate(df.iterrows()):\n",
    "    sample_id = int(fit.sample_id)\n",
    "    gt_params = random_params.iloc[sample_id].sort_index()\n",
    "    fit_params = pd.Series(fit.best_params, fit.params_name).sort_index()\n",
    "    \n",
    "    axonal_idxs = gt_params.index.str.contains('axonal')\n",
    "    somatic_idxs = gt_params.index.str.contains('somatic')\n",
    "    apical_idxs = gt_params.index.str.contains('apical')\n",
    "    \n",
    "    param_dist = distance.cosine(fit_params.values, gt_params.values)\n",
    "    param_dist_ax = distance.cosine(fit_params[axonal_idxs].values, gt_params[axonal_idxs].values)\n",
    "    param_dist_som = distance.cosine(fit_params[somatic_idxs].values, gt_params[somatic_idxs].values)\n",
    "    param_dist_ap = distance.cosine(fit_params[apical_idxs].values, gt_params[apical_idxs].values)\n",
    "    \n",
    "    param_distances.append(param_dist)\n",
    "    param_distances_axonal.append(param_dist_ax)\n",
    "    param_distances_somatic.append(param_dist_som)\n",
    "    param_distances_apical.append(param_dist_ap)\n",
    "    \n",
    "    \n",
    "    selected_keys = []\n",
    "    for k in gt_features_v[sample_id].keys():\n",
    "        if 'MEA' not in k:\n",
    "            selected_keys.append(k)\n",
    "        else:\n",
    "            if channels is not None:\n",
    "                if int(k[-1]) in channels:\n",
    "                    selected_keys.append(k)\n",
    "                else:\n",
    "                    selected_keys.append(k)\n",
    "    gt_feat, fitted_feat = [], []\n",
    "    gt_feat_soma, gt_feat_dend, gt_feat_mea = [], [], []\n",
    "    fitted_feat_soma, fitted_feat_dend, fitted_feat_mea = [], [], []\n",
    "    for k in selected_keys:\n",
    "        if k in gt_features_v[sample_id] and k in fitted_features_v[i]:\n",
    "            gt_feat.append(gt_features_v[sample_id][k])\n",
    "            fitted_feat.append(fitted_features_v[i][k])\n",
    "            if 'soma' in k:\n",
    "                gt_feat_soma.append(gt_features_v[sample_id][k])\n",
    "                fitted_feat_soma.append(fitted_features_v[i][k])\n",
    "            if 'dend' in k:\n",
    "                gt_feat_dend.append(gt_features_v[sample_id][k])\n",
    "                fitted_feat_dend.append(fitted_features_v[i][k])\n",
    "            if 'mea' in k:\n",
    "                gt_feat_mea.append(gt_features_v[sample_id][k])\n",
    "                fitted_feat_mea.append(fitted_features_v[i][k])\n",
    "                \n",
    "    feature_dist = distance.cosine(fitted_feat, gt_feat)\n",
    "    feature_dist_soma = distance.cosine(fitted_feat_soma, gt_feat_soma)\n",
    "    feature_dist_dend = distance.cosine(fitted_feat_dend, gt_feat_dend)\n",
    "    feature_dist_mea = distance.cosine(fitted_feat_mea, gt_feat_mea)\n",
    "    \n",
    "    feature_distances.append(feature_dist)\n",
    "    feat_soma_dist.append(feature_dist_soma)    \n",
    "    feat_dend_dist.append(feature_dist_dend)    \n",
    "    feat_mea_dist.append(feature_dist_mea)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['param_dist'] = param_distances\n",
    "df['param_dist_apical'] = param_distances_apical\n",
    "df['param_dist_axonal'] = param_distances_axonal\n",
    "df['param_dist_somatic'] = param_distances_somatic\n",
    "\n",
    "df['feat_dist'] = feature_distances\n",
    "df['feat_dist_soma'] = feat_soma_dist\n",
    "df['feat_dist_dend'] = feat_dend_dist\n",
    "df['feat_dist_mea'] = feat_mea_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plt.figure()\n",
    "ax1 = fig1.add_subplot(111)\n",
    "sns.barplot(data=df, x='feature_set', y='param_dist', hue='sample_id', ax=ax1, alpha=0.5)\n",
    "ax1.set_title(\"All params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = plt.figure()\n",
    "ax21 = fig2.add_subplot(131)\n",
    "ax22 = fig2.add_subplot(132)\n",
    "ax23 = fig2.add_subplot(133)\n",
    "sns.barplot(data=df, x='feature_set', y='param_dist_somatic', hue='sample_id', ax=ax21, alpha=0.5, ci=None)\n",
    "sns.barplot(data=df, x='feature_set', y='param_dist_axonal', hue='sample_id', ax=ax22, alpha=0.5, ci=None)\n",
    "sns.barplot(data=df, x='feature_set', y='param_dist_apical', hue='sample_id', ax=ax23, alpha=0.5, ci=None)\n",
    "\n",
    "ax21.set_title(\"Somatic params\")\n",
    "ax22.set_title(\"Axonal params\")\n",
    "ax23.set_title(\"Apical params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3 = plt.figure()\n",
    "ax3 = fig3.add_subplot(111)\n",
    "sns.boxenplot(data=df, x='feature_set', y='feat_dist', hue='sample_id', ax=ax3)\n",
    "ax3.set_title('All features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig4 = plt.figure()\n",
    "ax41 = fig4.add_subplot(131)\n",
    "ax42 = fig4.add_subplot(132)\n",
    "ax43 = fig4.add_subplot(133)\n",
    "sns.boxenplot(data=df, x='feature_set', y='feat_dist_soma', hue='sample_id', ax=ax41)#, alpha=0.5, ci=None)\n",
    "sns.boxenplot(data=df, x='feature_set', y='feat_dist_dend', hue='sample_id', ax=ax42)#, alpha=0.5, ci=None)\n",
    "sns.boxenplot(data=df, x='feature_set', y='feat_dist_mea', hue='sample_id', ax=ax43)#, alpha=0.5, ci=None)\n",
    "\n",
    "ax41.set_title(\"Somatic features\")\n",
    "ax42.set_title(\"Dend features\")\n",
    "ax43.set_title(\"MEA features\")\n",
    "ax42.set_yticks([])\n",
    "ax42.set_yticklabels([])\n",
    "ax42.set_ylabel('')\n",
    "ax43.set_yticks([])\n",
    "ax43.set_yticklabels([])\n",
    "ax43.set_ylabel('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_id = 0\n",
    "df_fit = df[df.sample_id == str(gt_id)]\n",
    "fitted = np.array(fitted_responses)[np.array(df_fit.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {'soma': 'C0', 'bap': 'C1', 'extra': 'C2'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_list = []\n",
    "feature_sets = []\n",
    "for i in range(len(df_1)):\n",
    "    color_list.append(colors[df_fit.iloc[i].feature_set])\n",
    "    feature_sets.append(df_fit.iloc[i].feature_set)\n",
    "\n",
    "soma_idxs = np.where(np.array(feature_sets) == 'soma')\n",
    "bap_idxs = np.where(np.array(feature_sets) == 'bap')\n",
    "extra_idxs = np.where(np.array(feature_sets) == 'extra')\n",
    "\n",
    "fitted_soma = fitted[soma_idxs]\n",
    "fitted_bap = fitted[bap_idxs]\n",
    "fitted_extra = fitted[extra_idxs]\n",
    "\n",
    "color_list.append('k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_soma = plot_multiple_responses(responses_list=np.concatenate((fitted_soma, [gt_responses[gt_id]])), \n",
    "                                   colors=['C0'] * len(fitted_soma) + ['k'], return_fig=True)\n",
    "fig_soma.suptitle(\"Soma features\", fontsize=30, y=0.98)\n",
    "fig_soma.subplots_adjust(top=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_bap = plot_multiple_responses(responses_list=np.concatenate((fitted_bap, [gt_responses[gt_id]])), \n",
    "                                  colors=['C1'] * len(fitted_bap) + ['k'], return_fig=True)\n",
    "fig_bap.suptitle(\"BAP features\", fontsize=30, y=0.98)\n",
    "fig_bap.subplots_adjust(top=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_extra = plot_multiple_responses(responses_list=np.concatenate((fitted_extra, [gt_responses[gt_id]])), \n",
    "                                    colors=['C2'] * len(fitted_extra) + ['k'], return_fig=True)\n",
    "fig_extra.suptitle(\"Extra features\", fontsize=30, y=0.98)\n",
    "fig_extra.subplots_adjust(top=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot extracellular action potentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_eap_soma = plt.figure(figsize=(7, 12))\n",
    "ax_eap_soma = fig_eap_soma.add_subplot(111)\n",
    "for i, fitted in enumerate(fitted_soma):\n",
    "    eap = l5pc_evaluator.calculate_eap(responses=fitted, protocols=fitness_protocols,\n",
    "                                       protocol_name='Step1')\n",
    "    eap_norm = eap / np.max(np.abs(eap), 1, keepdims=True)\n",
    "    mu.plot_mea_recording(eap_norm, \n",
    "                          probe, colors='C0', ax=ax_eap_soma, vscale=2)\n",
    "eap = l5pc_evaluator.calculate_eap(responses=gt_responses[gt_id], protocols=fitness_protocols,\n",
    "                                   protocol_name='Step1')\n",
    "eap_norm = eap / np.max(np.abs(eap), 1, keepdims=True)\n",
    "mu.plot_mea_recording(eap_norm, \n",
    "                      probe, colors='k', ax=ax_eap_soma, vscale=2)\n",
    "ax_eap_soma.set_title(\"Soma features\", fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_eap_bap = plt.figure(figsize=(7, 12))\n",
    "ax_eap_bap = fig_eap_bap.add_subplot(111)\n",
    "for i, fitted in enumerate(fitted_bap):\n",
    "    eap = l5pc_evaluator.calculate_eap(responses=fitted, protocols=fitness_protocols,\n",
    "                                       protocol_name='Step1')\n",
    "    eap_norm = eap / np.max(np.abs(eap), 1, keepdims=True)\n",
    "    mu.plot_mea_recording(eap_norm, \n",
    "                          probe, colors='C1', ax=ax_eap_bap, vscale=2)\n",
    "eap = l5pc_evaluator.calculate_eap(responses=gt_responses[gt_id], protocols=fitness_protocols,\n",
    "                                   protocol_name='Step1')\n",
    "eap_norm = eap / np.max(np.abs(eap), 1, keepdims=True)\n",
    "mu.plot_mea_recording(eap_norm, \n",
    "                      probe, colors='k', ax=ax_eap_bap, vscale=2)\n",
    "ax_eap_bap.set_title(\"BAP features\", fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_eap_extra = plt.figure(figsize=(7, 12))\n",
    "ax_eap_extra = fig_eap_extra.add_subplot(111)\n",
    "for i, fitted in enumerate(fitted_extra):\n",
    "    eap = l5pc_evaluator.calculate_eap(responses=fitted, protocols=fitness_protocols,\n",
    "                                       protocol_name='Step1')\n",
    "    eap_norm = eap / np.max(np.abs(eap), 1, keepdims=True)\n",
    "    mu.plot_mea_recording(eap_norm, \n",
    "                          probe, colors='C2', ax=ax_eap_extra, vscale=2)\n",
    "eap = l5pc_evaluator.calculate_eap(responses=gt_responses[gt_id], protocols=fitness_protocols,\n",
    "                                   protocol_name='Step1')\n",
    "eap_norm = eap / np.max(np.abs(eap), 1, keepdims=True)\n",
    "mu.plot_mea_recording(eap_norm, \n",
    "                      probe, colors='k', ax=ax_eap_extra, vscale=2)\n",
    "ax_eap_extra.set_title(\"Extra features\", fontsize=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
