{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Analyze and evaluate optimization output\n",
    "\n",
    "This final notebook uses the `runs.pkl` file created in notebook 2 and it analyzes:\n",
    "\n",
    "- the distance between different feature sets in the parameter space\n",
    "- the distance between different feature sets in the feature space\n",
    "- the distance between different feature sets in the extracellular signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "import bluepyopt as bpopt\n",
    "import bluepyopt.ephys as ephys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import distance\n",
    "import MEAutility as mu\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from scipy.stats import kruskal, mannwhitneyu, wilcoxon\n",
    "\n",
    "import multimodalfitting as mf\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load GT params and optimization output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general\n",
    "model_name = \"hay_ais\"\n",
    "probe_type = \"planar\" # linear \n",
    "data_base_folder = Path(f\"/Users/abuccino/Documents/Codes/modeling/multimodal-fitting/multimodalfitting/fitting_data/data_210927\")\n",
    "\n",
    "cell_models_folder = Path(\"..\") / \"cell_models\"\n",
    "model_folder = cell_models_folder / model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = data_base_folder / f\"{model_name}_ecode_probe_{probe_type}\"\n",
    "\n",
    "# change this with folder containing your pkl file\n",
    "result_folder = Path(\"..\") / \"results\" / '211124' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = mf.create_ground_truth_model(model_name=model_name,\n",
    "                                    release=False)\n",
    "cell_release = mf.create_ground_truth_model(model_name=model_name,\n",
    "                                            release=True)\n",
    "\n",
    "probe = mf.define_electrode(probe_type=probe_type)\n",
    "\n",
    "param_names = [param.name for param in cell.params.values() if not param.frozen]\n",
    "# sim = ephys.simulators.LFPySimulator(cell, cvode_active=True, electrode=probe, mechs_folders=model_folder)\n",
    "\n",
    "params_release = {}\n",
    "for param in cell_release.params_by_names(param_names):\n",
    "    params_release[param.name] = param.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol_for_eap = \"IDrest_300\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_file_name = \"runs.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open(result_folder / pkl_file_name, 'rb'))\n",
    "df_optimization = pd.DataFrame(data)\n",
    "df_model = df_optimization.query(f\"model == '{model_name}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_soma = df_model.query(\"feature_set == 'soma'\")\n",
    "opt_extra = df_model.query(\"feature_set == 'extra'\")\n",
    "print(f\"Somatic optimizations: {len(opt_soma)}\")\n",
    "print(f\"Extra optimizations: {len(opt_extra)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "min_evals = 3000\n",
    "color_strategy = {\"all\": \"C1\", \"sections\": \"C2\", \"single\": \"C3\"}\n",
    "\n",
    "keep_idxs_soma = []\n",
    "for idx, row in opt_soma.iterrows():\n",
    "    if max(row[\"nevals\"]) > min_evals:\n",
    "        keep_idxs_soma.append(idx)\n",
    "        ax.plot(row[\"nevals\"], \n",
    "                row[\"logbook\"].select(\"min\"),\n",
    "                color=\"C0\",\n",
    "                ls='-', \n",
    "                lw=0.8,\n",
    "                alpha=0.75)\n",
    "    else:\n",
    "        ax.plot(row[\"nevals\"], \n",
    "                row[\"logbook\"].select(\"min\"),\n",
    "                color=\"C0\",\n",
    "                ls='--', \n",
    "                lw=0.5,\n",
    "                alpha=0.75)\n",
    "keep_idx_extra = []\n",
    "for idx, row in opt_extra.iterrows():\n",
    "    #print(max(row['nevals']))\n",
    "    if max(row[\"nevals\"]) > min_evals:\n",
    "        keep_idx_extra.append(idx)\n",
    "        ax.plot(row[\"nevals\"], \n",
    "                row[\"logbook\"].select(\"min\"),\n",
    "                color=color_strategy[row[\"extra_strategy\"]],\n",
    "                ls='-', \n",
    "                lw=0.8,\n",
    "                alpha=0.75, \n",
    "                label=idx)\n",
    "    else:\n",
    "        ax.plot(row[\"nevals\"], \n",
    "                row[\"logbook\"].select(\"min\"),\n",
    "                color=color_strategy[row[\"extra_strategy\"]],\n",
    "                ls='--', \n",
    "                lw=0.5,\n",
    "                alpha=0.75, \n",
    "                label=idx)\n",
    "ax.set_title(\"Min fitness\")\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "ax.set_xlabel(\"Neval\")\n",
    "ax.set_ylabel(\"Min fitness\")\n",
    "ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load protocols and original features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocols_file = data_folder / \"efeatures\" / \"protocols_BPO_all.json\"\n",
    "feature_file = data_folder / \"efeatures\" / \"features_BPO_all.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_kwargs = dict(fs=20,\n",
    "                    fcut=[300, 6000],\n",
    "                    filt_type=\"filtfilt\",\n",
    "                    ms_cut=[3, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eva_extra = mf.create_evaluator(\n",
    "    model_name=model_name,\n",
    "    feature_set=\"extra\",\n",
    "    extra_strategy=\"all\",\n",
    "    protocols_with_lfp=\"IDrest_300\",\n",
    "    **extra_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for extra_strategy in np.unique(opt_extra.extra_strategy):\n",
    "    \n",
    "    eva_ex = mf.create_evaluator(\n",
    "        model_name=model_name,\n",
    "        feature_set=\"extra\",\n",
    "        extra_strategy=extra_strategy,\n",
    "        protocols_with_lfp=\"IDrest_300\",\n",
    "        **extra_kwargs\n",
    "    )\n",
    "    print(f\"Strategy {extra_strategy} --> num features {len(eva_ex.fitness_calculator.objectives)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_soma = opt_soma.loc[keep_idxs_soma]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_soma.best_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_extra = opt_extra.loc[keep_idx_extra]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute release responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_release = eva_extra.run_protocols(eva_extra.fitness_protocols.values(), param_values=params_release)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eap_release = mf.utils.calculate_eap(responses=responses_release, protocols=eva_extra.fitness_protocols, \n",
    "                                     protocol_name=protocol_for_eap, **extra_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_release = {}\n",
    "for obj in eva_extra.fitness_calculator.objectives:\n",
    "    features_release[obj.features[0].name] = {}\n",
    "    if len(obj.features) == 1:\n",
    "        feat_value = obj.features[0].calculate_feature(responses_release)\n",
    "        feat_score = obj.features[0].calculate_score(responses_release)\n",
    "        features_release[obj.features[0].name][\"value\"] = feat_value\n",
    "        features_release[obj.features[0].name][\"score\"] = feat_score\n",
    "    else:\n",
    "        print(f\"More than one feature for objective: {obj.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"soma\" example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_soma = np.argmin(opt_soma.best_fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_sample_soma = opt_soma.iloc[best_soma]\n",
    "params_sample_soma_dict = {k: v for k, v in zip(param_names, params_sample_soma.best_params)}\n",
    "display(params_sample_soma.best_fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_soma = eva_extra.run_protocols(eva_extra.fitness_protocols.values(), param_values=params_sample_soma_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_best_soma = {}\n",
    "for obj in eva_extra.fitness_calculator.objectives:\n",
    "    features_best_soma[obj.features[0].name] = {}\n",
    "    if len(obj.features) == 1:\n",
    "        feat_value = obj.features[0].calculate_feature(response_soma)\n",
    "        feat_score = obj.features[0].calculate_score(response_soma)\n",
    "        features_best_soma[obj.features[0].name][\"value\"] = feat_value\n",
    "        features_best_soma[obj.features[0].name][\"score\"] = feat_score\n",
    "    else:\n",
    "        print(f\"More than one feature for objective: {obj.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eap_soma = mf.utils.calculate_eap(responses=response_soma, protocols=eva_extra.fitness_protocols, \n",
    "                                  protocol_name=protocol_for_eap, **extra_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf.plot_multiple_responses([responses_release, response_soma], colors=[\"k\", \"C0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf.plot_multiple_eaps([responses_release, response_soma], eva_extra.fitness_protocols, probe,\n",
    "                            protocol_name=protocol_for_eap, colors=[\"k\", \"C0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eap_dist_soma = distance.cosine(eap_release.ravel(), eap_soma.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"extra\" example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_all = opt_extra.query(\"extra_strategy == 'all'\")\n",
    "opt_sections = opt_extra.query(\"extra_strategy == 'sections'\")\n",
    "opt_single = opt_extra.query(\"extra_strategy == 'single'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_all = np.argmin(opt_all.best_fitness)\n",
    "best_sections = np.argmin(opt_sections.best_fitness)\n",
    "best_single = np.argmin(opt_single.best_fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_sample_all = opt_all.iloc[best_all]\n",
    "params_sample_dict_all = {k: v for k, v in zip(param_names, params_sample_all.best_params)}\n",
    "display(\"ALL\", params_sample_all.best_fitness)\n",
    "\n",
    "params_sample_sections = opt_sections.iloc[best_sections]\n",
    "params_sample_dict_sections = {k: v for k, v in zip(param_names, params_sample_sections.best_params)}\n",
    "display(\"SECTIONS\", params_sample_sections.best_fitness)\n",
    "\n",
    "params_sample_single = opt_single.iloc[best_single]\n",
    "params_sample_dict_single = {k: v for k, v in zip(param_names, params_sample_single.best_params)}\n",
    "display(\"SINGLE\", params_sample_single.best_fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_all = eva_extra.run_protocols(eva_extra.fitness_protocols.values(), \n",
    "                                       param_values=params_sample_dict_all)\n",
    "response_sections = eva_extra.run_protocols(eva_extra.fitness_protocols.values(), \n",
    "                                            param_values=params_sample_dict_sections)\n",
    "response_single = eva_extra.run_protocols(eva_extra.fitness_protocols.values(), \n",
    "                                          param_values=params_sample_dict_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eap_all = mf.utils.calculate_eap(responses=response_all, protocols=eva_extra.fitness_protocols, \n",
    "                                 protocol_name=protocol_for_eap, **extra_kwargs)\n",
    "eap_sections = mf.utils.calculate_eap(responses=response_sections, protocols=eva_extra.fitness_protocols, \n",
    "                                      protocol_name=protocol_for_eap, **extra_kwargs)\n",
    "eap_single = mf.utils.calculate_eap(responses=response_single, protocols=eva_extra.fitness_protocols, \n",
    "                                    protocol_name=protocol_for_eap, **extra_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_best_all = {}\n",
    "for obj in eva_extra.fitness_calculator.objectives:\n",
    "    features_best_all[obj.features[0].name] = {}\n",
    "    if len(obj.features) == 1:\n",
    "        feat_value = obj.features[0].calculate_feature(response_all)\n",
    "        feat_score = obj.features[0].calculate_score(response_all)\n",
    "        features_best_all[obj.features[0].name][\"value\"] = feat_value\n",
    "        features_best_all[obj.features[0].name][\"score\"] = feat_score\n",
    "    else:\n",
    "        print(f\"More than one feature for objective: {obj.name}\")\n",
    "        \n",
    "features_best_sections = {}\n",
    "for obj in eva_extra.fitness_calculator.objectives:\n",
    "    features_best_sections[obj.features[0].name] = {}\n",
    "    if len(obj.features) == 1:\n",
    "        feat_value = obj.features[0].calculate_feature(response_sections)\n",
    "        feat_score = obj.features[0].calculate_score(response_sections)\n",
    "        features_best_sections[obj.features[0].name][\"value\"] = feat_value\n",
    "        features_best_sections[obj.features[0].name][\"score\"] = feat_score\n",
    "    else:\n",
    "        print(f\"More than one feature for objective: {obj.name}\")\n",
    "        \n",
    "features_best_single = {}\n",
    "for obj in eva_extra.fitness_calculator.objectives:\n",
    "    features_best_single[obj.features[0].name] = {}\n",
    "    if len(obj.features) == 1:\n",
    "        feat_value = obj.features[0].calculate_feature(response_single)\n",
    "        feat_score = obj.features[0].calculate_score(response_single)\n",
    "        features_best_single[obj.features[0].name][\"value\"] = feat_value\n",
    "        features_best_single[obj.features[0].name][\"score\"] = feat_score\n",
    "    else:\n",
    "        print(f\"More than one feature for objective: {obj.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf.plot_multiple_responses([responses_release, response_all, response_sections, response_single], \n",
    "                           colors=[\"k\", \"C1\", \"C2\", \"C3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_all = mf.plot_multiple_eaps([responses_release, response_soma, response_all], \n",
    "                               eva_extra.fitness_protocols, probe,\n",
    "                               protocol_name=protocol_for_eap, \n",
    "                               colors=[\"k\", \"C0\", \"C1\"])\n",
    "ax_all.set_title(\"ALL\")\n",
    "\n",
    "ax_sec = mf.plot_multiple_eaps([responses_release, response_soma, response_sections], \n",
    "                               eva_extra.fitness_protocols, probe,\n",
    "                               protocol_name=protocol_for_eap, \n",
    "                               colors=[\"k\", \"C0\", \"C2\"])\n",
    "ax_sec.set_title(\"SECTIONS\")\n",
    "\n",
    "ax_sin = mf.plot_multiple_eaps([responses_release, response_soma, response_single], \n",
    "                               eva_extra.fitness_protocols, probe,\n",
    "                               protocol_name=protocol_for_eap, \n",
    "                               colors=[\"k\", \"C0\", \"C3\"])\n",
    "ax_sin.set_title(\"SINGLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eap_dist_all = distance.cosine(eap_release.ravel(), eap_all.ravel())\n",
    "eap_dist_sections = distance.cosine(eap_release.ravel(), eap_sections.ravel())\n",
    "eap_dist_single = distance.cosine(eap_release.ravel(), eap_single.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cosine dist SOMA\", eap_dist_soma)\n",
    "print(\"Cosine dist EXTRA ALL\", eap_dist_all)\n",
    "print(\"Cosine dist EXTRA SECTIONS\", eap_dist_sections)\n",
    "print(\"Cosine dist EXTRA SINGLE\", eap_dist_single)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare best-fitted models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_gt_dict = {}\n",
    "for obj in eva_extra.fitness_calculator.objectives:\n",
    "    feat_gt_dict[obj.features[0].name] = {}\n",
    "    if len(obj.features) == 1:\n",
    "        feat_value = obj.features[0].calculate_feature(responses_release)\n",
    "        feat_score = obj.features[0].calculate_score(responses_release)\n",
    "        feat_gt_dict[obj.features[0].name][\"value\"] = feat_value\n",
    "        feat_gt_dict[obj.features[0].name][\"score\"] = feat_score\n",
    "    else:\n",
    "        print(f\"More than one feature for objective: {obj.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best_soma = opt_soma.iloc[best_soma].to_frame().transpose()\n",
    "df_best_soma[\"extra_strategy\"] = \"soma\"\n",
    "df_best_soma[\"responses\"] = [response_soma]\n",
    "df_best_soma[\"eap\"] = [eap_soma]\n",
    "df_best_soma[\"eap_dist\"] = eap_dist_soma\n",
    "\n",
    "df_best_all = opt_all.iloc[best_all].to_frame().transpose()\n",
    "df_best_all[\"responses\"] = [response_all]\n",
    "df_best_all[\"eap\"] = [eap_all]\n",
    "df_best_all[\"eap_dist\"] = eap_dist_all\n",
    "\n",
    "\n",
    "df_best_sections = opt_sections.iloc[best_sections].to_frame().transpose()\n",
    "df_best_sections[\"responses\"] = [response_sections]\n",
    "df_best_sections[\"eap\"] = [eap_sections]\n",
    "df_best_sections[\"eap_dist\"] = eap_dist_sections\n",
    "\n",
    "df_best_single = opt_single.iloc[best_single].to_frame().transpose()\n",
    "df_best_single[\"responses\"] = [response_single]\n",
    "df_best_single[\"eap\"] = [eap_single]\n",
    "df_best_single[\"eap_dist\"] = eap_dist_single\n",
    "\n",
    "df_test = pd.concat([df_best_soma, df_best_all, df_best_sections, df_best_single])\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eap_dist_single"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare parameters \n",
    "\n",
    "Here we normalize the parameters based on the boundaries and compute the relative difference to GT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_json = model_folder / \"parameters.json\"\n",
    "\n",
    "with param_json.open() as f:\n",
    "    params = json.load(f)\n",
    "\n",
    "param_boundaries = {}\n",
    "for param in params:\n",
    "    if \"bounds\" in param:\n",
    "        if isinstance(param['sectionlist'], list):\n",
    "            for sec in param['sectionlist']:\n",
    "                param_boundaries[f\"{param['param_name']}_{sec}\"] = param[\"bounds\"]\n",
    "        else:\n",
    "            sec = param['sectionlist']\n",
    "            param_boundaries[f\"{param['param_name']}_{sec}\"] = param[\"bounds\"]\n",
    "\n",
    "# scale params_release by boundaries\n",
    "params_release_norm = {}\n",
    "for param_name, param_val in params_release.items():\n",
    "    bounds = param_boundaries[param_name]\n",
    "    param_norm = (param_val - bounds[0]) / (bounds[1] - bounds[0])\n",
    "    params_release_norm[param_name] = param_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_release_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set_array = []\n",
    "seed_array = []\n",
    "param_name_array = []\n",
    "param_value_array = []\n",
    "param_norm_array = []\n",
    "release_value_array = []\n",
    "release_norm_array = []\n",
    "diff_with_release_array = []\n",
    "section_array = []\n",
    "\n",
    "for i, (index, opt) in enumerate(df_test.iterrows()):\n",
    "    params_dict = {k: v for k, v in zip(param_names, opt.best_params)}\n",
    "    \n",
    "    for param_name, param_value in params_dict.items():\n",
    "        feature_set_array.append(opt.extra_strategy)\n",
    "        seed_array.append(opt.seed)   \n",
    "        param_name_array.append(param_name)\n",
    "        param_value_array.append(param_value)\n",
    "        section_array.append(param_name.split(\"_\")[-1])\n",
    "        release_value_array.append(params_release[param_name])\n",
    "        release_norm_array.append(params_release_norm[param_name])\n",
    "        # compute norm value\n",
    "        bounds = param_boundaries[param_name]\n",
    "        param_norm = (param_value - bounds[0]) / (bounds[1] - bounds[0])\n",
    "        param_norm_array.append(param_norm)\n",
    "        diff_with_release_array.append(abs(param_norm - params_release_norm[param_name]))\n",
    "\n",
    "for param_name, param_value in params_release.items():\n",
    "    feature_set_array.append(\"GT\")\n",
    "    seed_array.append(0)   \n",
    "    param_name_array.append(param_name)\n",
    "    param_value_array.append(param_value)\n",
    "    section_array.append(param_name.split(\"_\")[-1])\n",
    "    release_value_array.append(params_release[param_name])\n",
    "    release_norm_array.append(params_release_norm[param_name])\n",
    "    # compute norm value\n",
    "    bounds = param_boundaries[param_name]\n",
    "    param_norm = (param_value - bounds[0]) / (bounds[1] - bounds[0])\n",
    "    param_norm_array.append(param_norm)\n",
    "    diff_with_release_array.append(0)\n",
    "        \n",
    "df_params = pd.DataFrame({\"seed\": seed_array, \"feature_set\": feature_set_array, \"param_name\": param_name_array,\n",
    "                          \"param_value\": param_value_array, \"param_norm\": param_norm_array, \n",
    "                          \"release_value\": release_value_array, \"release_norm\": release_norm_array,\n",
    "                          \"diff_release\": diff_with_release_array, \"section\": section_array})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_gt = df_params.query(\"feature_set != 'GT'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall parameter diff\n",
    "plt.figure()\n",
    "sns.boxenplot(data=df_no_gt, y=\"feature_set\", x=\"diff_release\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.barplot(data=df_no_gt.query(\"section == 'somatic'\"), y=\"param_name\", x=\"diff_release\", hue=\"feature_set\",\n",
    "            orientation=\"horizontal\")\n",
    "plt.figure()\n",
    "sns.boxenplot(data=df_no_gt.query(\"section == 'somatic'\"), y=\"feature_set\", x=\"diff_release\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.barplot(data=df_no_gt.query(\"section == 'apical'\"), y=\"param_name\", x=\"diff_release\", hue=\"feature_set\",\n",
    "            orientation=\"horizontal\")\n",
    "plt.figure()\n",
    "sns.boxenplot(data=df_no_gt.query(\"section == 'apical'\"), y=\"feature_set\", x=\"diff_release\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.barplot(data=df_no_gt.query(\"section == 'basal'\"), y=\"param_name\", x=\"diff_release\", hue=\"feature_set\",\n",
    "            orientation=\"horizontal\")\n",
    "plt.figure()\n",
    "sns.boxenplot(data=df_no_gt.query(\"section == 'basal'\"), y=\"feature_set\", x=\"diff_release\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.barplot(data=df_no_gt.query(\"section == 'segment'\"), y=\"param_name\", x=\"diff_release\", hue=\"feature_set\",\n",
    "            orientation=\"horizontal\")\n",
    "plt.figure()\n",
    "sns.boxenplot(data=df_no_gt.query(\"section == 'segment'\"), y=\"feature_set\", x=\"diff_release\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name_array = []\n",
    "feature_set_array = []\n",
    "feature_score_array = []\n",
    "feature_type_array = []\n",
    "\n",
    "feature_dicts = dict(soma=features_best_soma, \n",
    "                     all=features_best_all, \n",
    "                     sections=features_best_sections,\n",
    "                     single=features_best_single)\n",
    "\n",
    "for feature_set, feats in feature_dicts.items():\n",
    "    for feat_name, feat_dict in feats.items():\n",
    "        feature_set_array.append(feature_set)\n",
    "        feature_name_array.append(feat_name)\n",
    "        if \"MEA\" not in feat_name:\n",
    "            feature_type_array.append(\"intra\")\n",
    "        else:\n",
    "            feature_type_array.append(\"extra\")\n",
    "        feature_score_array.append(feat_dict[\"score\"])\n",
    "        \n",
    "df_feats = pd.DataFrame({\"feature_set\": feature_set_array, \"feat_name\": feature_name_array,\n",
    "                         \"feat_score\": feature_score_array, \"feature_type\": feature_type_array})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_set_array = []\n",
    "# seed_array = []\n",
    "# feature_name_array = []\n",
    "# feature_value_array = []\n",
    "# feature_score_array = []\n",
    "# feature_type_array = []\n",
    "# extra_strategy_array = []\n",
    "\n",
    "# for i, feats in enumerate(feats_soma):\n",
    "#     for feat_name, feat_dict in feats.items():\n",
    "#         feature_set_array.append(\"soma\")\n",
    "#         seed_array.append(i)\n",
    "#         feature_name_array.append(feat_name)\n",
    "#         if \"MEA\" not in feat_name:\n",
    "#             feature_type_array.append(\"soma\")\n",
    "#             feature_value_array.append(feat_dict[\"value\"])\n",
    "#         else:\n",
    "#             feature_type_array.append(\"MEA\")\n",
    "#             feature_value_array.append(np.nan)\n",
    "#         feature_score_array.append(feat_dict[\"score\"])\n",
    "#         extra_strategy_array.append(\"soma\")\n",
    "    \n",
    "# for i, feats in enumerate(feats_extra):\n",
    "#     for feat_name, feat_dict in feats.items():\n",
    "#         feature_set_array.append(\"extra\")\n",
    "#         seed_array.append(i)\n",
    "#         feature_name_array.append(feat_name)\n",
    "#         if \"MEA\" not in feat_name:\n",
    "#             feature_type_array.append(\"soma\")\n",
    "#             feature_value_array.append(feat_dict[\"value\"])\n",
    "#         else:\n",
    "#             feature_type_array.append(\"MEA\")\n",
    "#             feature_value_array.append(np.nan)\n",
    "#         feature_score_array.append(feat_dict[\"score\"])\n",
    "#         extra_strategy_array.append(strategy_extra[i])\n",
    "    \n",
    "# df_feats = pd.DataFrame({\"seed\": seed_array, \"feature_set\": feature_set_array, \"feat_name\": feature_name_array,\n",
    "#                          \"feat_value\": feature_value_array, \"feat_score\": feature_score_array,\n",
    "#                          \"feat_type\": feature_type_array, \"extra_strategy\": extra_strategy_array})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_feats.query(\"feature_type == 'extra'\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.boxplot(data=df_feats.query(\"feature_type == 'intra'\"), y=\"feature_set\", x=\"feat_score\", ax=ax)\n",
    "# g = sns.swarmplot(data=df_feats.query(\"feat_type == 'soma'\"), x=\"extra_strategy\", y=\"feat_score\", ax=ax)\n",
    "ax.set_ylabel(\"Feature scores (intracellular)\", fontsize=12)\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "ax.set_title(\"Intracellular features\", fontsize=15)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.boxplot(data=df_feats.query(\"feature_type == 'extra'\"), \n",
    "              y=\"feature_set\", x=\"feat_score\", ax=ax)\n",
    "# g = sns.swarmplot(data=df_feats.query(\"feat_type == 'MEA'\"), \n",
    "#                   x=\"feature_set\", y=\"feat_score\", ax=ax)\n",
    "ax.set_ylabel(\"Feature scores (extracellular)\", fontsize=12)\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "ax.set_title(\"Extracellular features\", fontsize=15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare EAP distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.barplot(data=df_test, x=\"extra_strategy\", y=\"eap_dist\", ax=ax)\n",
    "ax.set_ylabel(\"Cosine distance\", fontsize=12)\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "ax.set_title(\"Extracellular difference\", fontsize=15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
