{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Create runs.pkl file from optimisazion checkpoints\n",
    "\n",
    "After running the model optimizations with the `run_optimizations.py` script, this notebook checks the optimization outputs and it creates a summary file called `runs.pkl` in the `optimization_results` folder.\n",
    "\n",
    "The `runs.pkl` is used in notebooks 3-4 to evaluate and compare the optimization outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import glob\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import multimodalfitting as mf\n",
    "from multimodalfitting.utils import load_checkpoint, read_checkpoint\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder = Path('../optimization_results/checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = []\n",
    "eva_json = []\n",
    "\n",
    "for p in results_folder.iterdir():\n",
    "    \n",
    "    if \"tmp\" in p.suffix or \"runs\" in p.name or \"json\" in p.suffix:\n",
    "        continue\n",
    "    \n",
    "    print(p)\n",
    "    runs.append(load_checkpoint(p))\n",
    "    eva_json.append(p.parent / f\"{p.stem}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = set([run[\"model\"] for run in runs])\n",
    "colors_model = {m: \"C{}\".format(i) for i,m in enumerate(models)}\n",
    "print(colors_model)\n",
    "colors_set = {\"soma\": \"C0\", \"extra\": \"C1\"} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "for run in runs:\n",
    "\n",
    "    ax.plot(run[\"nevals\"], \n",
    "            run[\"logbook\"].select(\"min\"),\n",
    "            color=colors_model[run[\"model\"]],\n",
    "            ls='--', \n",
    "            lw=1,\n",
    "            alpha=0.75,\n",
    "            label=run[\"model\"])\n",
    "    \n",
    "    ax.scatter([run[\"nevals\"][-1]], \n",
    "               [np.sum(run[\"hof\"][0].fitness.values)],\n",
    "               color=colors_model[run[\"model\"]],\n",
    "               alpha=0.75)\n",
    "    \n",
    "ax.set_xlabel(\"Number of evaluations\", size=\"x-large\")\n",
    "ax.set_ylabel(\"Minimum fitness (std)\", size=\"x-large\")\n",
    "\n",
    "ax.set_yscale('log')\n",
    "ax.legend(fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "for run in runs:\n",
    "\n",
    "    ax.plot(run[\"nevals\"], \n",
    "            run[\"logbook\"].select(\"min\"),\n",
    "            color=colors_set[run[\"feature_set\"]],\n",
    "            ls='--', \n",
    "            lw=1,\n",
    "            alpha=0.75,\n",
    "            label=run[\"feature_set\"])\n",
    "    \n",
    "    ax.scatter([run[\"nevals\"][-1]], \n",
    "               [np.sum(run[\"hof\"][0].fitness.values)],\n",
    "               color=colors_set[run[\"feature_set\"]],\n",
    "               alpha=0.75)\n",
    "    \n",
    "ax.set_xlabel(\"Number of evaluations\", size=\"x-large\")\n",
    "ax.set_ylabel(\"Minimum fitness (std)\", size=\"x-large\")\n",
    "\n",
    "ax.set_yscale('log')\n",
    "ax.legend(fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results to pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(str(results_folder / \"runs.pkl\"), 'wb') as fp:\n",
    "    pickle.dump(runs, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (optional) Check optimization responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (run, eva) in zip(runs, eva_json):\n",
    "    \n",
    "    eva_args = json.load(eva.open(\"r\"))\n",
    "    evaluator = mf.create_evaluator(**eva_args)\n",
    "    \n",
    "    best_params = evaluator.param_dict(run[\"best_params\"])\n",
    "    responses = evaluator.run_protocols(protocols=evaluator.fitness_protocols.values(), \n",
    "                                        param_values=best_params)\n",
    "    fig = mf.plot_responses(responses, return_fig=True)\n",
    "    fig.subplots_adjust(top=0.85)\n",
    "    fig.suptitle(eva.stem, y=0.95, fontsize=20)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
