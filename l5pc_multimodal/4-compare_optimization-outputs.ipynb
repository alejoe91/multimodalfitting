{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Compare optimization results\n",
    "\n",
    "In this notebook we use the previously optimized parameters to assess the performance of different optimization strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "#!nrnivmodl mechanisms\n",
    "import bluepyopt as bpopt\n",
    "import bluepyopt.ephys as ephys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import MEAutility as mu\n",
    "import json\n",
    "import numpy\n",
    "import time\n",
    "import numpy as np\n",
    "import LFPy\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import l5pc_model\n",
    "import l5pc_evaluator\n",
    "import l5pc_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_id = 3 # [0, ..., n_samples]\n",
    "offspring_size = 250\n",
    "max_ngen = 50\n",
    "channels = [0, 6, 7, 10, 15]\n",
    "nchannels=len(channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_params_file = 'config/params/random.csv'\n",
    "random_params = pd.read_csv(random_params_file, index_col='index')\n",
    "gt_params = random_params.iloc[sample_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gt_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_params = gt_params.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get checkpoints\n",
    "checkpoints_folder = Path('checkpoints/')\n",
    "cp_soma_file = checkpoints_folder / f'random_{sample_id}' / f'soma_off{offspring_size}_ngen{max_ngen}_{nchannels}chan.pkl'\n",
    "cp_bap_file = checkpoints_folder / f'random_{sample_id}' / f'bap_off{offspring_size}_ngen{max_ngen}_{nchannels}chan.pkl'\n",
    "cp_extra_file = checkpoints_folder / f'random_{sample_id}' / f'extra_off{offspring_size}_ngen{max_ngen}_{nchannels}chan.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_soma = pickle.load(open(cp_soma_file, 'rb'))\n",
    "cp_bap = pickle.load(open(cp_bap_file, 'rb'))\n",
    "cp_extra = pickle.load(open(cp_extra_file, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hof_soma = cp_soma['halloffame']\n",
    "hof_bap = cp_bap['halloffame']\n",
    "hof_extra = cp_extra['halloffame']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_extra['generation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep = l5pc_evaluator.prepare_optimization('extra', sample_id, offspring_size=offspring_size, channels=channels,\n",
    "                                           map_function = None)\n",
    "evaluator = prep['evaluator']\n",
    "fitness_calculator = prep['objectives_calculator']\n",
    "fitness_protocols = prep['protocols']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_soma = best_params = evaluator.param_dict(hof_soma[0])\n",
    "best_bap = best_params = evaluator.param_dict(hof_bap[0])\n",
    "best_extra = best_params = evaluator.param_dict(hof_extra[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_soma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_bap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_error_soma = {}\n",
    "rel_error_bap = {}\n",
    "rel_error_extra = {}\n",
    "\n",
    "for param, gt_value in gt_params.items():\n",
    "    rel_error_soma[param] = np.abs((gt_value - best_soma[param]) / gt_value)\n",
    "    rel_error_bap[param] = np.abs((gt_value - best_bap[param]) / gt_value)    \n",
    "    rel_error_extra[param] = np.abs((gt_value - best_extra[param]) / gt_value)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_error_soma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_error_bap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_error_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(list(rel_error_soma.values())), \n",
    "      np.sum(list(rel_error_bap.values())), \n",
    "      np.sum(list(rel_error_extra.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_evolution(logbook, color, label=None, ax=None):\n",
    "    if ax is None:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "    \n",
    "    gens = []\n",
    "    avgs = []\n",
    "    stds = []\n",
    "    mins = []\n",
    "    maxs = []\n",
    "    \n",
    "    for log in logbook:\n",
    "        gens.append(log['gen'])\n",
    "        avgs.append(log['avg'])        \n",
    "        stds.append(log['std'])        \n",
    "        mins.append(log['min'])        \n",
    "        maxs.append(log['max'])      \n",
    "    \n",
    "    gens = np.array(gens)\n",
    "    avgs = np.array(avgs)\n",
    "    stds = np.array(stds)\n",
    "    mins = np.array(mins)\n",
    "    maxs = np.array(maxs)\n",
    "    \n",
    "#     ax.plot(gens, avgs, color=color, label=label)\n",
    "    ax.plot(gens, mins, color=color, label=label)\n",
    "#     ax.plot(gens, maxs, color=color,  ls='--', alpha=0.3)\n",
    "#     ax.fill(gens, avgs, mins, color=color, alpha=0.3)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_evolution(cp_soma['logbook'], color='C0', label='soma')\n",
    "ax = plot_evolution(cp_bap['logbook'], color='C1', label='bap', ax=ax)\n",
    "ax = plot_evolution(cp_extra['logbook'], color='C2', label='extra', ax=ax)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_responses = evaluator.run_protocols(protocols=fitness_protocols.values(), param_values=gt_params)\n",
    "best_responses_soma = evaluator.run_protocols(protocols=fitness_protocols.values(), param_values=best_soma)\n",
    "best_responses_bap = evaluator.run_protocols(protocols=fitness_protocols.values(), param_values=best_bap)\n",
    "best_responses_extra = evaluator.run_protocols(protocols=fitness_protocols.values(), param_values=best_extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l5pc_plot.plot_multiple_responses([original_responses, best_responses_bap, best_responses_soma, best_responses_extra])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l5pc_plot.plot_multiple_responses([original_responses, best_responses_extra])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare extracellular action potentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## HELPER FUNCTIONS ##\n",
    "def _construct_somatic_efel_trace(responses, somatic_recording_name, stim_start, stim_end):\n",
    "    \"\"\"Construct trace that can be passed to eFEL\"\"\"\n",
    "\n",
    "    trace = {}\n",
    "    if somatic_recording_name not in responses:\n",
    "        return None\n",
    "\n",
    "    if responses[somatic_recording_name] is None:\n",
    "        return None\n",
    "\n",
    "    response = responses[somatic_recording_name]\n",
    "\n",
    "    trace['T'] = response['time']\n",
    "    trace['V'] = response['voltage']\n",
    "    trace['stim_start'] = [stim_start]\n",
    "    trace['stim_end'] = [stim_end]\n",
    "\n",
    "    return trace\n",
    "\n",
    "def _setup_efel(threshold=None, interp_step=None, double_settings=None, int_settings=None):\n",
    "    \"\"\"Set up efel before extracting the feature\"\"\"\n",
    "\n",
    "    import efel\n",
    "    efel.reset()\n",
    "\n",
    "    if threshold is not None:\n",
    "        efel.setThreshold(threshold)\n",
    "\n",
    "    if interp_step is not None:\n",
    "        efel.setDoubleSetting('interp_step', interp_step)\n",
    "\n",
    "    if double_settings is not None:\n",
    "        for setting_name, setting_value in double_settings.items():\n",
    "            efel.setDoubleSetting(setting_name, setting_value)\n",
    "\n",
    "    if int_settings is not None:\n",
    "        for setting_name, setting_value in int_settings.items():\n",
    "            efel.setIntSetting(setting_name, setting_value)\n",
    "            \n",
    "\n",
    "def _get_peak_times(responses, somatic_recording_name, stim_start, stim_end, raise_warnings=False, **efel_kwargs):\n",
    "\n",
    "    efel_trace = _construct_somatic_efel_trace(responses, somatic_recording_name, stim_start, stim_end)\n",
    "\n",
    "    if efel_trace is None:\n",
    "        peak_times = None\n",
    "    else:\n",
    "        _setup_efel(**efel_kwargs)\n",
    "\n",
    "        import efel\n",
    "        peaks = efel.getFeatureValues([efel_trace], ['peak_time'], raise_warnings=raise_warnings)\n",
    "        peak_times = peaks[0]['peak_time']\n",
    "\n",
    "        efel.reset()\n",
    "\n",
    "    return peak_times\n",
    "\n",
    "def _interpolate_response(response, fs=20.):\n",
    "    from scipy.interpolate import interp1d\n",
    "\n",
    "    x = response['time']\n",
    "    y = response['voltage']\n",
    "    f = interp1d(x, y, axis=1)\n",
    "    xnew = np.arange(np.min(x), np.max(x), 1. / fs)\n",
    "    ynew = f(xnew)  # use interpolation function returned by `interp1d`\n",
    "\n",
    "    response_new = {}\n",
    "    response_new['time'] = xnew\n",
    "    response_new['voltage'] = ynew\n",
    "\n",
    "    return response_new\n",
    "\n",
    "\n",
    "def _filter_response(response, fcut=[0.5, 6000], order=2, filt_type='lfilter'):\n",
    "    import scipy.signal as ss\n",
    "    fs = 1 / np.mean(np.diff(response['time'])) * 1000\n",
    "    fn = fs / 2.\n",
    "\n",
    "    trace = response['voltage']\n",
    "\n",
    "    if isinstance(fcut, (float, int, np.float, np.integer)):\n",
    "        btype = 'highpass'\n",
    "        band = fcut / fn\n",
    "    else:\n",
    "        assert isinstance(fcut, (list, np.ndarray)) and len(fcut) == 2\n",
    "        btype = 'bandpass'\n",
    "        band = np.array(fcut) / fn\n",
    "\n",
    "    b, a = ss.butter(order, band, btype=btype)\n",
    "\n",
    "    if len(trace.shape) == 2:\n",
    "        if filt_type == 'filtfilt':\n",
    "            filtered = ss.filtfilt(b, a, trace, axis=1)\n",
    "        else:\n",
    "            filtered = ss.lfilter(b, a, trace, axis=1)\n",
    "    else:\n",
    "        if filt_type == 'filtfilt':\n",
    "            filtered = ss.filtfilt(b, a, trace)\n",
    "        else:\n",
    "            filtered = ss.lfilter(b, a, trace)\n",
    "\n",
    "    response_new = {}\n",
    "    response_new['time'] = response['time']\n",
    "    response_new['voltage'] = filtered\n",
    "\n",
    "    return response_new\n",
    "\n",
    "\n",
    "def _upsample_wf(waveforms, upsample):\n",
    "    from scipy.signal import resample_poly\n",
    "    ndim = len(waveforms.shape)\n",
    "    waveforms_up = resample_poly(waveforms, up=upsample, down=1, axis=ndim-1)\n",
    "\n",
    "    return waveforms_up\n",
    "\n",
    "\n",
    "def _get_waveforms(response, peak_times, snippet_len_ms):\n",
    "    times = response['time']\n",
    "    traces = response['voltage']\n",
    "\n",
    "    assert np.std(np.diff(times)) < 0.001 * np.mean(np.diff(times)), \"Sampling frequency must be constant\"\n",
    "\n",
    "    fs = 1. / np.mean(np.diff(times))  # kHz\n",
    "\n",
    "    reference_frames = (peak_times * fs).astype(int)\n",
    "\n",
    "    if isinstance(snippet_len_ms, (tuple, list, np.ndarray)):\n",
    "        snippet_len_before = int(snippet_len_ms[0] * fs)\n",
    "        snippet_len_after = int(snippet_len_ms[1] * fs)\n",
    "    else:\n",
    "        snippet_len_before = int((snippet_len_ms + 1) / 2 * fs)\n",
    "        snippet_len_after = int((snippet_len_ms - snippet_len_before) * fs)\n",
    "\n",
    "    num_snippets = len(peak_times)\n",
    "    if len(traces.shape) == 2:\n",
    "        num_channels = traces.shape[0]\n",
    "    else:\n",
    "        num_channels = 1\n",
    "        traces = traces[np.newaxis, :]\n",
    "    num_frames = len(times)\n",
    "    snippet_len_total = int(snippet_len_before + snippet_len_after)\n",
    "    waveforms = np.zeros((num_snippets, num_channels, snippet_len_total), dtype=traces.dtype)\n",
    "\n",
    "    for i in range(num_snippets):\n",
    "        snippet_chunk = np.zeros((num_channels, snippet_len_total), dtype=traces.dtype)\n",
    "        if 0 <= reference_frames[i] < num_frames:\n",
    "            snippet_range = np.array([int(reference_frames[i]) - snippet_len_before,\n",
    "                                      int(reference_frames[i]) + snippet_len_after])\n",
    "            snippet_buffer = np.array([0, snippet_len_total], dtype='int')\n",
    "            # The following handles the out-of-bounds cases\n",
    "            if snippet_range[0] < 0:\n",
    "                snippet_buffer[0] -= snippet_range[0]\n",
    "                snippet_range[0] -= snippet_range[0]\n",
    "            if snippet_range[1] >= num_frames:\n",
    "                snippet_buffer[1] -= snippet_range[1] - num_frames\n",
    "                snippet_range[1] -= snippet_range[1] - num_frames\n",
    "            snippet_chunk[:, snippet_buffer[0]:snippet_buffer[1]] = traces[:, snippet_range[0]:snippet_range[1]]\n",
    "        waveforms[i] = snippet_chunk\n",
    "\n",
    "    return waveforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_eap(responses, protocol_name, protocols, fs=20, fcut=1,\n",
    "                  ms_cut=[2, 10], upsample=10, skip_first_spike=True, skip_last_spike=True, \n",
    "                  raise_warnings=False, verbose=False, **efel_kwargs):\n",
    "    \n",
    "    assert \"Step\" in protocol_name\n",
    "    stimulus = protocols[protocol_name].stimuli[0]\n",
    "    stim_start = stimulus.step_delay\n",
    "    stim_end = stimulus.step_delay + stimulus.step_duration\n",
    "    efel_kwargs['threshold'] = -20\n",
    "    \n",
    "    somatic_recording_name = f'{protocol_name}.soma.v'\n",
    "    extra_recording_name = f'{protocol_name}.MEA.LFP'\n",
    "    \n",
    "    peak_times = _get_peak_times(responses, somatic_recording_name, stim_start, stim_end,\n",
    "                                 raise_warnings=raise_warnings, **efel_kwargs)\n",
    "\n",
    "    if len(peak_times) > 1 and skip_first_spike:\n",
    "        peak_times = peak_times[1:]\n",
    "\n",
    "    if len(peak_times) > 1 and skip_last_spike:\n",
    "        peak_times = peak_times[:-1]\n",
    "        \n",
    "    if responses[extra_recording_name] is not None:\n",
    "        response = responses[extra_recording_name]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    if np.std(np.diff(response['time'])) > 0.001 * np.mean(np.diff(response['time'])):\n",
    "        assert fs is not None\n",
    "        if verbose:\n",
    "            print('interpolate')\n",
    "        response_interp = _interpolate_response(response, fs=fs)\n",
    "    else:\n",
    "        response_interp = response\n",
    "\n",
    "    if fcut is not None:\n",
    "        if verbose:\n",
    "            print('filter enabled')\n",
    "        response_filter = _filter_response(response_interp, fcut=fcut)\n",
    "    else:\n",
    "        if verbose:\n",
    "            print('filter disabled')\n",
    "        response_filter = response_interp\n",
    "\n",
    "    ewf = _get_waveforms(response_filter, peak_times, ms_cut)\n",
    "    mean_wf = np.mean(ewf, axis=0)\n",
    "    if upsample is not None:\n",
    "        if verbose:\n",
    "            print('upsample')\n",
    "        assert upsample > 0\n",
    "        upsample = int(upsample)\n",
    "        mean_wf_up = _upsample_wf(mean_wf, upsample)\n",
    "        fs_up = upsample * fs\n",
    "    else:\n",
    "        mean_wf_up = mean_wf\n",
    "        fs_up = fs\n",
    "\n",
    "    return mean_wf_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_wf_extra = calculate_eap(best_responses_extra, \"Step1\", evaluator.fitness_protocols) * 1000\n",
    "mean_wf_bap = calculate_eap(best_responses_bap, \"Step1\", evaluator.fitness_protocols) * 1000\n",
    "mean_wf_soma = calculate_eap(best_responses_soma, \"Step1\", evaluator.fitness_protocols) * 1000\n",
    "mean_wf_original = calculate_eap(original_responses, \"Step1\", evaluator.fitness_protocols) * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_wf_extra_n = mean_wf_extra / np.max(np.abs(mean_wf_extra), 1, keepdims=True)\n",
    "mean_wf_bap_n = mean_wf_extra / np.max(np.abs(mean_wf_bap), 1, keepdims=True)\n",
    "mean_wf_soma_n = mean_wf_extra / np.max(np.abs(mean_wf_soma), 1, keepdims=True)\n",
    "mean_wf_original_n = mean_wf_extra / np.max(np.abs(mean_wf_original), 1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_file = Path('config') / 'features' / f'random_{sample_id}'/ 'probe.json'\n",
    "probe, electrode = l5pc_evaluator.define_electrode(probe_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vscale = 1.5 * np.max(np.abs(mean_wf_original_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_extra = mu.plot_mea_recording(mean_wf_original_n, probe, colors='k', lw=2)\n",
    "mu.plot_mea_recording(mean_wf_soma_n, probe, colors='C0', ax=ax_extra)\n",
    "mu.plot_mea_recording(mean_wf_bap_n, probe, colors='C1', ax=ax_extra)\n",
    "mu.plot_mea_recording(mean_wf_extra_n, probe, colors='C2', ax=ax_extra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capability of the models to reproduce BAP-activated calcium spikes?\n",
    "\n",
    "It would be nice to show some functional output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
