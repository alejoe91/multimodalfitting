{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1b) Smart sampling the parameter space\n",
    "\n",
    "From the set of parameters estimated using multiple patch recordings (1 somatic, 2 apical dendrites), we simulate random perturbations using Latin Hypercube Sampling (LHS). \n",
    "\n",
    "First, we generate a large number of samples, then we select the samples which:\n",
    "\n",
    "- are the most distant between each other\n",
    "- which reproduce bAP firing\n",
    "- whose feature sets are also the most distant \n",
    "\n",
    "The random parameters are saved in the `config/params/smart_random.csv` and will be used to assess the fitting performance of different feature sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "from pyDOE import lhs\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from scipy.spatial import distance\n",
    "import MEAutility as mu\n",
    "import LFPy\n",
    "from copy import copy\n",
    "\n",
    "import bluepyopt as bpopt\n",
    "import bluepyopt.ephys as ephys\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2308)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import l5pc_model\n",
    "import l5pc_evaluator\n",
    "import l5pc_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_params = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "release_params = {\n",
    "    'gNaTs2_tbar_NaTs2_t.apical': 0.026145,\n",
    "    'gSKv3_1bar_SKv3_1.apical': 0.004226,\n",
    "    'gImbar_Im.apical': 0.000143,\n",
    "    'gNaTa_tbar_NaTa_t.axonal': 3.137968,\n",
    "    'gK_Tstbar_K_Tst.axonal': 0.089259,\n",
    "    'gamma_CaDynamics_E2.axonal': 0.002910,\n",
    "    'gNap_Et2bar_Nap_Et2.axonal': 0.006827,\n",
    "    'gSK_E2bar_SK_E2.axonal': 0.007104,\n",
    "    'gCa_HVAbar_Ca_HVA.axonal': 0.000990,\n",
    "    'gK_Pstbar_K_Pst.axonal': 0.973538,\n",
    "    'gSKv3_1bar_SKv3_1.axonal': 1.021945,\n",
    "    'decay_CaDynamics_E2.axonal': 287.198731,\n",
    "    'gCa_LVAstbar_Ca_LVAst.axonal': 0.008752,\n",
    "    'gamma_CaDynamics_E2.somatic': 0.000609,\n",
    "    'gSKv3_1bar_SKv3_1.somatic': 0.303472,\n",
    "    'gSK_E2bar_SK_E2.somatic': 0.008407,\n",
    "    'gCa_HVAbar_Ca_HVA.somatic': 0.000994,\n",
    "    'gNaTs2_tbar_NaTs2_t.somatic': 0.983955,\n",
    "    'decay_CaDynamics_E2.somatic': 210.485284,\n",
    "    'gCa_LVAstbar_Ca_LVAst.somatic': 0.000333\n",
    "}\n",
    "\n",
    "# load param configs for boundary values\n",
    "# param_configs = json.load(open('config/parameters.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_params = len(release_params)\n",
    "n_samples = 500  # number of random samples \n",
    "lim_dev = 0.3  # limits for each param are: [release_val-lim_dev*release_val, release_val+lim_dev*release_val] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latin hypercube sampling (normal 0-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_samples = lhs(n_params, samples=n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot(random_samples[:, 5], random_samples[:, 19], random_samples[:, 3], '*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute parameters limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if True, the limits of the params config are used. Otherwise, the realeas params +- lim_dev are used\n",
    "use_params_bounds = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_lims = {}\n",
    "\n",
    "for par, val in release_params.items():\n",
    "    dev = lim_dev * val\n",
    "    lims = [val - dev, val + dev]\n",
    "    \n",
    "    # check values based on param configs\n",
    "    for param in param_configs:\n",
    "        name, loc = par.split('.')\n",
    "        if param['param_name'] == name and param['sectionlist'] == loc:\n",
    "            if 'bounds' in param:\n",
    "                if use_params_bounds:\n",
    "                    lims = param['bounds']\n",
    "                else:\n",
    "                    if lims[0] < param['bounds'][0]:\n",
    "                        lims[0] = param['bounds'][0]\n",
    "                        print(f'Param {par} changed lower bound')                    \n",
    "                    if lims[1] > param['bounds'][1]:\n",
    "                        lims[1] = param['bounds'][1]\n",
    "                        print(f'Param {par} changed upper bound')\n",
    "                print(param['param_name'], lims, param['bounds'])\n",
    "\n",
    "    param_lims[par] = lims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_lims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_samples = np.zeros_like(random_samples)\n",
    "\n",
    "for i, sample in enumerate(random_samples):\n",
    "    for j, (par, parlim) in enumerate(param_lims.items()):\n",
    "        scaled_samples[i, j] = (parlim[1] - parlim[0]) * sample[j] + parlim[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in scaled_samples:\n",
    "    for j, (par, parlim) in enumerate(param_lims.items()):\n",
    "        assert parlim[0] < sample[j] < parlim[1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select *distant* parameters\n",
    "\n",
    "First we iteratively look for parameters distan from each other in the original normalized space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_target_samples = 3 # 50\n",
    "min_dist = 0.2\n",
    "target_samples_idxs = []\n",
    "it = 0\n",
    "max_iter = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "while it < max_iter:\n",
    "    if np.mod(it, 100) == 0:\n",
    "        print(f\"Iteration {it+1}/{max_iter}\")\n",
    "        \n",
    "    if len(target_samples_idxs) == 0:\n",
    "        random_sample_id = np.random.permutation(len(random_samples))[0]\n",
    "        print(f'Added {random_sample_id}')\n",
    "        target_samples_idxs.append(random_sample_id)\n",
    "    else:\n",
    "        # compute distances\n",
    "        all_samples = np.arange(len(scaled_samples))\n",
    "        dists = np.zeros((len(target_samples_idxs), len(random_samples)))\n",
    "        for i, target_id in enumerate(target_samples_idxs):\n",
    "            target = random_samples[target_id]\n",
    "            for j in all_samples:\n",
    "                dists[i, j] = distance.cosine(random_samples[j], target)\n",
    "        \n",
    "        cum_dist = []\n",
    "        possible_idxs = []\n",
    "        for col in all_samples:\n",
    "            if np.all(dists[:, col] > min_dist):\n",
    "                possible_idxs.append(col)\n",
    "                cum_dist.append(np.sum(dists[:, col]))\n",
    "        \n",
    "        if len(possible_idxs) > 0:\n",
    "            max_id = np.argmax(cum_dist)\n",
    "            random_sample_id = possible_idxs[max_id]\n",
    "            print(f'Added {random_sample_id}: Targets {len(target_samples_idxs)}')\n",
    "            dists = []\n",
    "            for t in target_samples_idxs:\n",
    "                dists.append(distance.cosine(random_samples[t], random_samples[random_sample_id]))\n",
    "            target_samples_idxs.append(random_sample_id)\n",
    "            \n",
    "    if len(target_samples_idxs) >= num_target_samples:\n",
    "        print(\"Found samples!\")\n",
    "        break\n",
    "    it += 1\n",
    "target_samples_idxs = np.array(target_samples_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(target_samples_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_params_mat = np.zeros((len(target_samples_idxs), len(target_samples_idxs)))\n",
    "for i in np.arange(len(target_samples_idxs)):\n",
    "    for j in np.arange(i+1, len(target_samples_idxs)):\n",
    "        p1 = random_samples[target_samples_idxs[i]]\n",
    "        p2 = random_samples[target_samples_idxs[j]]\n",
    "        cost = distance.cosine(p1, p2)\n",
    "        dist_params_mat[i, j] =  cost\n",
    "dist_params_array = dist_params_mat[dist_params_mat>0].ravel()\n",
    "\n",
    "plt.matshow(dist_params_mat)\n",
    "plt.colorbar()\n",
    "\n",
    "print(np.min(dist_params_array))\n",
    "print(np.max(dist_params_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_sc_params_mat = np.zeros((len(target_samples_idxs), len(target_samples_idxs)))\n",
    "for i in np.arange(len(target_samples_idxs)):\n",
    "    for j in np.arange(i+1, len(target_samples_idxs)):\n",
    "        p1 = scaled_samples[target_samples_idxs[i]]\n",
    "        p2 = scaled_samples[target_samples_idxs[j]]\n",
    "        cost = distance.cosine(p1, p2)\n",
    "        dist_sc_params_mat[i, j] =  cost\n",
    "dist_sc_params_array = dist_sc_params_mat[dist_sc_params_mat>0].ravel()\n",
    "\n",
    "plt.matshow(dist_sc_params_mat)\n",
    "plt.colorbar()\n",
    "\n",
    "print(np.min(dist_sc_params_array))\n",
    "print(np.max(dist_sc_params_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute full set of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_features(feature_list):\n",
    "    feature_vectors = []\n",
    "    for feature in feature_list:\n",
    "        feature_vector = {}\n",
    "        for prot, prot_dict in feature.items():\n",
    "            for loc, loc_feat in prot_dict.items():\n",
    "                for feat, feat_val in loc_feat.items():\n",
    "                    feature_vector[f'{prot}.{loc}.{feat}'] = feat_val[0]\n",
    "        feature_vectors.append(feature_vector)\n",
    "    return feature_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mea_positions = np.zeros((20, 3))\n",
    "mea_positions[:, 2] = 20\n",
    "mea_positions[:, 1] = np.linspace(-500, 1000, 20)\n",
    "probe = mu.return_mea(info={'pos': list([list(p) for p in mea_positions]), 'center': False, 'plane': 'xy'})\n",
    "electrode = LFPy.RecExtElectrode(probe=probe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu.plot_probe(probe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = None\n",
    "\n",
    "morphology = ephys.morphologies.NrnFileMorphology('morphology/C060114A7.asc', do_replace_axon=True)\n",
    "param_configs = json.load(open('config/parameters.json'))\n",
    "parameters = l5pc_model.define_parameters()\n",
    "mechanisms = l5pc_model.define_mechanisms()\n",
    "\n",
    "l5pc_cell = ephys.models.LFPyCellModel('l5pc', \n",
    "                                       v_init=-65., \n",
    "                                       morph=morphology, \n",
    "                                       mechs=mechanisms, \n",
    "                                       params=parameters)\n",
    "\n",
    "param_names = [param.name for param in l5pc_cell.params.values() if not param.frozen]      \n",
    "feature_set = 'all'\n",
    "\n",
    "print(f'Feature set {feature_set}')\n",
    "gt_responses = []\n",
    "\n",
    "if feature_set in [\"extra\", \"all\"]:\n",
    "    fitness_protocols = l5pc_evaluator.define_protocols(electrode) \n",
    "else:\n",
    "    fitness_protocols = l5pc_evaluator.define_protocols() \n",
    "\n",
    "if feature_set in [\"extra\", \"all\"]:\n",
    "    sim = ephys.simulators.LFPySimulator(LFPyCellModel=l5pc_cell, cvode_active=True, electrode=electrode)\n",
    "else:\n",
    "    sim = ephys.simulators.LFPySimulator(LFPyCellModel=l5pc_cell, cvode_active=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_samples = random_samples[target_samples_idxs]\n",
    "target_scaled_samples = scaled_samples[target_samples_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_params = pd.DataFrame(data=target_scaled_samples, columns=param_lims.keys(), \n",
    "                             index=[f'random_{i}' for i in range(len(target_samples_idxs))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "ax = sns.boxplot(data=random_params, orient='horizontal')\n",
    "fig = ax.get_figure()\n",
    "fig.subplots_adjust(left=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random_features = []\n",
    "random_responses = []\n",
    "\n",
    "for i, (index, params) in enumerate(random_params.iterrows()):\n",
    "    print(f'{i+1} / {len(random_params)}, {index}')\n",
    "    \n",
    "    feature_folder = f'config/features/{index}'\n",
    "    _, response, feature_dict = l5pc_evaluator.compute_feature_values(params, l5pc_cell, fitness_protocols, sim, \n",
    "                                                                      feature_set=feature_set, probe=probe, \n",
    "                                                                      channels=channels,\n",
    "                                                                      feature_folder=feature_folder,\n",
    "                                                                      save_to_file=False)\n",
    "    random_features.append(feature_dict)\n",
    "    random_responses.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loaded_features = []\n",
    "loaded_responses = []\n",
    "\n",
    "for i, (index, params) in enumerate(loaded_params.iterrows()):\n",
    "    print(f'{i+1} / {len(loaded_params)}, {index}')\n",
    "    display(params)\n",
    "    \n",
    "    feature_folder = f'config/features/{index}'\n",
    "    _, response, feature_dict = l5pc_evaluator.compute_feature_values(params, l5pc_cell, fitness_protocols, sim, \n",
    "                                                                      feature_set=feature_set, probe=probe, \n",
    "                                                                      channels=channels,\n",
    "                                                                      feature_folder=feature_folder,\n",
    "                                                                      save_to_file=False)\n",
    "    loaded_features.append(feature_dict)\n",
    "    loaded_responses.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_params.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l5pc_plot.plot_multiple_responses(loaded_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l5pc_plot.plot_multiple_responses(random_responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude params that do not express bAP firing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_features_v = vectorize_features(random_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_bap = []\n",
    "for i, gt in enumerate(list(random_features_v)):\n",
    "    bap_feat = [k for k in gt.keys() if 'bAP' in k]\n",
    "    if len(bap_feat) == 5:\n",
    "        complete_bap.append(i)\n",
    "bap_sample_idxs = np.array(complete_bap)\n",
    "print(f\"Samples with complete bAP response: {len(complete_bap)} / {len(random_features_v)}\")\n",
    "\n",
    "bap_features_v = np.array(random_features_v)[bap_sample_idxs]\n",
    "bap_responses = np.array(random_responses)[bap_sample_idxs]\n",
    "bap_scaled_samples = target_scaled_samples[bap_sample_idxs]\n",
    "bap_random_samples = target_samples[bap_sample_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can select a subset of extracellular channels to compute features on (if None, all channels are used)\n",
    "channels=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dist_feat_mat = np.zeros((len(bap_sample_idxs), len(bap_sample_idxs)))\n",
    "for i in np.arange(len(bap_sample_idxs)):\n",
    "    for j in np.arange(i+1, len(bap_sample_idxs)):\n",
    "        f1 = bap_features_v[i]\n",
    "        f2 = bap_features_v[j]\n",
    "        \n",
    "        selected_keys = []\n",
    "        for k in f1.keys():\n",
    "            if 'MEA' not in k:\n",
    "                selected_keys.append(k)\n",
    "            else:\n",
    "                if channels is not None:\n",
    "                    if int(k[-1]) in channels:\n",
    "                        selected_keys.append(k)\n",
    "                else:\n",
    "                    selected_keys.append(k)\n",
    "                        \n",
    "        f1_val, f2_val = [], []\n",
    "        for k in selected_keys:\n",
    "            if k in f1 and k in f2:\n",
    "                if np.isfinite(f1[k]) and np.isfinite(f2[k]):\n",
    "                    f1_val.append(f1[k])\n",
    "                    f2_val.append(f2[k])\n",
    "        cost = distance.cosine(f1_val, f2_val)\n",
    "        if np.isnan(cost):\n",
    "            print(f1_val, f2_val)\n",
    "        dist_feat_mat[i, j] =  cost\n",
    "        \n",
    "dist_feat_array = dist_feat_mat[dist_feat_mat>0].ravel()\n",
    "\n",
    "plt.matshow(dist_feat_mat)\n",
    "plt.colorbar()\n",
    "\n",
    "print(np.min(dist_feat_array))\n",
    "print(np.max(dist_feat_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select samples with the most distant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_final_samples = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dist_matrix symmetric\n",
    "dist_feat_sym = copy(dist_feat_mat)\n",
    "\n",
    "for i in np.arange(len(bap_sample_idxs)):\n",
    "    for j in np.arange(i+1, len(bap_sample_idxs)):\n",
    "        dist_feat_sym[j, i] = dist_feat_sym[i, j]\n",
    "plt.matshow(dist_feat_sym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select samples based on cumulative distance\n",
    "cum_dist = np.sum(dist_feat_sym, 0)\n",
    "max_dist_idxs = np.argsort(cum_dist)[::-1][:num_final_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cum_dist[max_dist_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_sample_idxs = max_dist_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_scaled_params = bap_scaled_samples[selected_sample_idxs]\n",
    "selected_random_params = bap_random_samples[selected_sample_idxs]\n",
    "selected_responses = bap_responses[selected_sample_idxs]\n",
    "selected_features_v = bap_features_v[selected_sample_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_sel_random_params_mat = np.zeros((len(selected_random_params), len(selected_random_params)))\n",
    "dist_sel_scaled_params_mat = np.zeros((len(selected_random_params), len(selected_random_params)))\n",
    "dist_sel_features_mat = np.zeros((len(selected_random_params), len(selected_random_params)))\n",
    "for i in np.arange(len(selected_random_params)):\n",
    "    for j in np.arange(i+1, len(selected_random_params)):\n",
    "        p1 = selected_random_params[i]\n",
    "        p2 = selected_random_params[j]\n",
    "        dist_sel_random_params_mat[i, j] =  distance.cosine(p1, p2)\n",
    "        \n",
    "        p1 = selected_scaled_params[i]\n",
    "        p2 = selected_scaled_params[j]\n",
    "        dist_sel_scaled_params_mat[i, j] =  distance.cosine(p1, p2)\n",
    "        \n",
    "        f1 = selected_features_v[i]\n",
    "        f2 = selected_features_v[j]\n",
    "        \n",
    "        selected_keys = []\n",
    "        for k in f1.keys():\n",
    "            if 'MEA' not in k:\n",
    "                selected_keys.append(k)\n",
    "            else:\n",
    "                if channels is not None:\n",
    "                    if int(k[-1]) in channels:\n",
    "                        selected_keys.append(k)\n",
    "                else:\n",
    "                    selected_keys.append(k)\n",
    "                        \n",
    "        f1_val, f2_val = [], []\n",
    "        for k in selected_keys:\n",
    "            if k in f1 and k in f2:\n",
    "                if np.isfinite(f1[k]) and np.isfinite(f2[k]):\n",
    "                    f1_val.append(f1[k])\n",
    "                    f2_val.append(f2[k])\n",
    "        dist_sel_features_mat[i, j] = distance.cosine(f1_val, f2_val)\n",
    "        \n",
    "# dist_params_array = dist_params_mat[dist_params_mat>0].ravel()\n",
    "\n",
    "plt.matshow(dist_sel_random_params_mat)\n",
    "plt.title(\"Norm params\")\n",
    "plt.colorbar()\n",
    "\n",
    "plt.matshow(dist_sel_scaled_params_mat)\n",
    "plt.title(\"Scaled params\")\n",
    "plt.colorbar()\n",
    "\n",
    "plt.matshow(dist_sel_features_mat)\n",
    "plt.title(\"Features\")\n",
    "plt.colorbar()\n",
    "\n",
    "# print(np.min(dist_params_array))\n",
    "# print(np.max(dist_params_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l5pc_plot.plot_multiple_responses(responses_list=selected_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3 = plt.figure()\n",
    "ax3 = fig3.add_subplot(111)\n",
    "cmap=plt.get_cmap('viridis')\n",
    "for i, gt in enumerate(selected_responses):\n",
    "    eap = l5pc_evaluator.calculate_eap(responses=gt, protocols=fitness_protocols,\n",
    "                                       protocol_name='Step3')\n",
    "    eap_norm = eap / np.max(np.abs(eap), 1, keepdims=True)\n",
    "    mu.plot_mea_recording(eap_norm, \n",
    "                          probe, colors=f\"C{i}\", ax=ax3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creata dataframe\n",
    "df_release = pd.DataFrame(data=release_params, index=['release'])\n",
    "df_random = pd.DataFrame(data=selected_scaled_params, columns=param_lims.keys(), \n",
    "                         index=[f'random_{i}' for i in range(len(selected_scaled_params))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "ax = sns.boxplot(data=df_random, orient='horizontal')\n",
    "fig = ax.get_figure()\n",
    "fig.subplots_adjust(left=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double check that responses are correct!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_params_file = 'config/params/smart_random.csv'\n",
    "loaded_params = pd.read_csv(loaded_params_file, index_col='index')\n",
    "loaded_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = None\n",
    "\n",
    "morphology = ephys.morphologies.NrnFileMorphology('morphology/C060114A7.asc', do_replace_axon=True)\n",
    "param_configs = json.load(open('config/parameters.json'))\n",
    "parameters = l5pc_model.define_parameters()\n",
    "mechanisms = l5pc_model.define_mechanisms()\n",
    "\n",
    "l5pc_cell = ephys.models.LFPyCellModel('l5pc', \n",
    "                                       v_init=-65., \n",
    "                                       morph=morphology, \n",
    "                                       mechs=mechanisms, \n",
    "                                       params=parameters)\n",
    "\n",
    "param_names = [param.name for param in l5pc_cell.params.values() if not param.frozen]      \n",
    "feature_set = 'all'\n",
    "\n",
    "print(f'Feature set {feature_set}')\n",
    "gt_responses = []\n",
    "\n",
    "if feature_set in [\"extra\", \"all\"]:\n",
    "    fitness_protocols = l5pc_evaluator.define_protocols(electrode) \n",
    "else:\n",
    "    fitness_protocols = l5pc_evaluator.define_protocols() \n",
    "\n",
    "if feature_set in [\"extra\", \"all\"]:\n",
    "    sim = ephys.simulators.LFPySimulator(LFPyCellModel=l5pc_cell, cvode_active=True, electrode=electrode)\n",
    "else:\n",
    "    sim = ephys.simulators.LFPySimulator(LFPyCellModel=l5pc_cell, cvode_active=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = []\n",
    "\n",
    "for i, (index, params) in enumerate(random_params.iterrows()):\n",
    "    print(f'{i+1} / {len(random_params)}, {index}')\n",
    "    \n",
    "    feature_folder = f'config/features/{index}'\n",
    "    _, response, feature_dict = l5pc_evaluator.compute_feature_values(params, l5pc_cell, fitness_protocols, sim, \n",
    "                                                                      feature_set=feature_set, probe=probe, \n",
    "                                                                      channels=channels,\n",
    "                                                                      feature_folder=feature_folder,\n",
    "                                                                      save_to_file=False)\n",
    "    responses.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l5pc_plot.plot_multiple_responses(responses_list=responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l5pc_cell.freeze(params)\n",
    "l5pc_cell.instantiate(sim=sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sec in l5pc_cell.LFPyCell.allseclist:\n",
    "    print(sec, sec.Ra, sec.cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    print(p.name, p.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save random and releas parameters to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_params:\n",
    "    params_folder = Path('config/params')\n",
    "\n",
    "    if not params_folder.is_dir():\n",
    "        os.makedirs(params_folder)\n",
    "\n",
    "    release_params_file = params_folder / 'release.csv'\n",
    "    random_params_file = params_folder / 'smart_random.csv'\n",
    "\n",
    "    df_release.to_csv(release_params_file, index_label='index')\n",
    "    df_random.to_csv(random_params_file, index_label='index')    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
